{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th6gTo_1vt1n"
   },
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na3nfkze_NmF"
   },
   "source": [
    "If you are not using Google Colab, you need not run this. The purpose of this element is to navigate to the files on Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "8XeYsxujwhsE",
    "outputId": "4251c545-3fae-4573-dd5e-29e6a4c47b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/data_583\n",
      "breed_labels.csv     test_images\t\ttrain_metadata\n",
      "color_labels.csv     test_metadata\t\ttrain_sentiment\n",
      "picked_pictures.npy  test_sentiment\t\ttrain_sentiment_parsed.csv\n",
      "state_labels.csv     test_sentiment_parsed.csv\n",
      "test\t\t     train\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount my Google Drrive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Go to the directory with the 583 data\n",
    "os.chdir('/content/drive/My Drive/data_583')\n",
    "!pwd\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mDreCUSLvt1o",
    "outputId": "b674d558-768a-418c-90d2-ef531971e8ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "numeric_cols = [\n",
    "    'Age',\n",
    "    'Quantity', 'Fee', 'State',\n",
    "    'VideoAmt', 'PhotoAmt', 'Type'\n",
    "]\n",
    "\n",
    "one_hot_cols = {\n",
    "    #'Type': 2, \n",
    "    'Breed1': 307, 'Breed2': 307,\n",
    "    'Gender': 3, 'Color1': 7, 'Color2': 7,\n",
    "    'Color3': 7,\n",
    "    'MaturitySize': 5,\n",
    "    'FurLength': 4, 'Vaccinated': 3,\n",
    "    'Dewormed': 3, 'Sterilized': 3,\n",
    "    'Health': 4, 'State': 15\n",
    "}\n",
    "\n",
    "def one_hot_encode(df, col, num_class=None, labels=None, inplace=False):\n",
    "    ''' Takes in dataframe df and replaces col with num_class columns\n",
    "        For example, use as follows\n",
    "        for col, num_class in data.one_hot_cols.items():\n",
    "            one_hot_encode(train_df, col, num_class)\n",
    "    '''\n",
    "    # get the true values from data\n",
    "    column_values = np.sort(df[col].dropna().unique())\n",
    "    if num_class == None:\n",
    "        num_class = len(column_values)\n",
    "    if num_class == 2:\n",
    "        # These can just be boolean\n",
    "        if inplace:\n",
    "            df[col] = (df[col] == column_values[0]).astype(int)\n",
    "        else:\n",
    "            return (df[col] == column_values[0]).astype(int)\n",
    "    else:        \n",
    "        if labels is not None:\n",
    "            res = np.zeros((len(df), num_class))\n",
    "            for i, label in enumerate(labels):\n",
    "                if inplace:\n",
    "                    df[col+'_'+str(label)] = (df[col] == label).astype(int)\n",
    "                else:\n",
    "                    one_hot = np.zeros(num_class)\n",
    "                    one_hot[i] = 1\n",
    "                    res[df[col] == label] = one_hot\n",
    "        else:\n",
    "            res = np.zeros((len(df), num_class))\n",
    "            for i in range(num_class):\n",
    "                if (i >= len(column_values)):\n",
    "                    break # Index out of bounds\n",
    "                cur_value = column_values[i]\n",
    "\n",
    "                if inplace:\n",
    "                    df[col+'_'+str(cur_value)] = (df[col] == cur_value).astype(int)\n",
    "                else:\n",
    "                    one_hot = np.zeros(num_class)\n",
    "                    one_hot[i] = 1\n",
    "                    res[df[col] == cur_value] = one_hot\n",
    "    \n",
    "        if inplace:\n",
    "            # delete original column\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "def load_data(fname):\n",
    "    return pd.read_csv(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NFovwkcnECIJ",
    "outputId": "274311a5-2571-466b-8ec0-dc669f2a22ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nohe = {\\n    k: train_embedding(k, dim=4)\\n    for k in one_hot_cols\\n}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "def load_train_ohe(lbl):\n",
    "    dta = load_data('data/train/train.csv')\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for i, row in dta.iterrows():\n",
    "        x = row[lbl]\n",
    "        y = row['AdoptionSpeed']\n",
    "        \n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def train_embedding(name, dim=8):\n",
    "    print('Training embedding for', name)\n",
    "    \n",
    "    # Extract data\n",
    "    W, Z = load_train_ohe(name)\n",
    "    Ws = sorted(list(set(W)))\n",
    "    mapping = {c: i for i, c in enumerate(Ws)}\n",
    "    W = [mapping[w] for w in W]\n",
    "    Z = to_categorical(Z)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Embedding, Dense, Flatten\n",
    "    \n",
    "    # The embedding layer\n",
    "    emb = Embedding(len(W), dim, input_length=1)\n",
    "\n",
    "    # Make a training model for the embedding\n",
    "    model = Sequential()\n",
    "    model.add(emb)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    # Train the embedding to best predict the label (pretrain the labels)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    #model.summary()\n",
    "    model.fit(np.array(W), Z, epochs=8, validation_split=0.2)\n",
    "    \n",
    "    # Reduce the model\n",
    "    model = Sequential()\n",
    "    model.add(emb)\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    X = model.predict(np.array([[i] for i in range(len(mapping))]))\n",
    "    mapping = {\n",
    "        c: list(X[mapping[c]])\n",
    "        for c in mapping\n",
    "    }\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "# Generate an embedder for each of the one hot encodable models\n",
    "\"\"\"\n",
    "ohe = {\n",
    "    k: train_embedding(k, dim=4)\n",
    "    for k in one_hot_cols\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rFddqRDNVnw"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_pet_files(regdir):\n",
    "    \"\"\" Extracts all of the files associated with each pet listed\n",
    "    by the 'PetID' tag.\n",
    "\n",
    "    regdir - The directory containing the files\n",
    "\n",
    "    returns a dictionary containing keypairs (k, v) such that v\n",
    "    matches the regex (k\\-.*) where k is the key (a valid PetID).\n",
    "    \"\"\"\n",
    "    fname = os.path.join(regdir, 'picked_pictures.npy')\n",
    "    \n",
    "    print(f\"Images will be loaded from {fname}\")\n",
    "    return np.load(fname, allow_pickle=True).item()\n",
    "\n",
    "def load_pet_pics(regdir):\n",
    "    \"\"\" Extracts all of the files associated with each pet listed\n",
    "    by the 'PetID' tag.\n",
    "\n",
    "    regdir - The directory containing the files\n",
    "\n",
    "    returns a dictionary containing keypairs (k, v) such that v\n",
    "    matches the regex (k\\-.*) where k is the key (a valid PetID).\n",
    "    \"\"\"\n",
    "    if os.path.isfile(os.path.join(regdir + 'picked_pictures.npy')):\n",
    "        print(\"Images loaded from existing file\")\n",
    "        return np.load(os.path.join(regdir + 'picked_pictures.npy'), allow_pickle=True).item()\n",
    "    pfiles = {}\n",
    "\n",
    "    # Extract the pet names\n",
    "    for f in tqdm(os.listdir(regdir), desc='Loading Pet Files'):\n",
    "        # Extract the name\n",
    "        n = f[:f.index('-')]\n",
    "        url = os.path.join(regdir, f)\n",
    "        \n",
    "        if n in pfiles:\n",
    "            # Add to the entry\n",
    "            pfiles[n].append(img)\n",
    "\n",
    "        else:\n",
    "            # Add a new entry\n",
    "            pfiles[n] = [img]\n",
    "\n",
    "    np.save(os.path.join(regdir + 'picked_pictures.npy'), pfiles)\n",
    "    return pfiles\n",
    "\n",
    "def load_train_data(is_train = True):\n",
    "    # Get the annotations for each pet\n",
    "    dta = load_data('data/train/train.csv' if is_train else 'data/test/test.csv')\n",
    "     \n",
    "    # Get the pet pictures\n",
    "    try:\n",
    "        petpics = load_pet_files('data/') if is_train else load_pet_pics('data/test_images')\n",
    "    except:\n",
    "        print('Could not load pet pictures')\n",
    "        petpics = {}\n",
    "\n",
    "    # Get the state ids\n",
    "    states = load_data('data/state_labels.csv')\n",
    "    states = states['StateID'].tolist()\n",
    "\n",
    "    # Load parsed sentiment\n",
    "    sentiment = load_data('data/{}_sentiment_parsed.csv'.format('train' if is_train else 'test'))\n",
    "\n",
    "    X_num = []\n",
    "    X_pic = []\n",
    "\n",
    "    Y = []\n",
    "    \n",
    "    # Build a single object to store the X values\n",
    "    X = [X_num, X_pic]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for k in one_hot_cols:\n",
    "        one_hot_encode(dta, k, inplace=True)\n",
    "        print('One hot encoded', k)\n",
    "        \"\"\"\n",
    "    \n",
    "    print('Constructing attribute data')\n",
    "    for i, row in dta.iterrows():\n",
    "        # Save the numeric values\n",
    "        vals = list(row[numeric_cols])\n",
    "        \n",
    "        #state = [x == row['State'] for x in states] + [row['Gender'] == i for i in range(1,4)]\n",
    "        #assert(sum(state) == 1)\n",
    "        \n",
    "        # Add all of the valid one-hot encodings\n",
    "        #state = [row[k] for k in dta if any(q in k for q in one_hot_cols)]\n",
    "            \n",
    "        x = list(vals)# + state\n",
    "        \n",
    "            \n",
    "        # Join sentiment on PetID\n",
    "        s = sentiment[sentiment['PetID'] == row['PetID']]\n",
    "        \n",
    "        for col in s:\n",
    "            if col not in row:\n",
    "                row[col] = s.iloc[0][col]\n",
    "                x.append(row[col])\n",
    "        \n",
    "        # Add the one-hot encodings\n",
    "        x += list(row[one_hot_cols])\n",
    "        \n",
    "        \"\"\"\n",
    "        # Apply the one hot encodings\n",
    "        for col in ohe:\n",
    "            if row[col] in ohe[col]:\n",
    "                x.extend(ohe[col][row[col]])\n",
    "            else:\n",
    "                x.extend(ohe[col][0])\n",
    "        \"\"\"\n",
    "        \n",
    "        # Save the pictures\n",
    "        if row['PetID'] in petpics:\n",
    "            X_pic.append(petpics[row['PetID']])\n",
    "        else:\n",
    "            X_pic.append([])\n",
    "            \n",
    "        # Save the data pair\n",
    "        X_num.append(np.array(x))\n",
    "        \n",
    "        if is_train:\n",
    "            Y.append(row['AdoptionSpeed'])\n",
    "        else:\n",
    "            Y.append(row['PetID'])\n",
    "\n",
    "    # Laziness\n",
    "    if len(X) == 1:\n",
    "        X = np.array(X[0])\n",
    "    else:\n",
    "        X = list(map(np.array, X))\n",
    "\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    return (X, Y)\n",
    "\n",
    "def load_image(img_file, size=64):\n",
    "    # print('img file:', img_file)\n",
    "    img = Image.open(img_file)\n",
    "    img = img.resize((size, size), Image.ANTIALIAS)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "b6sUBRbzvt1r",
    "outputId": "78a1e0c8-698e-4321-cb14-ca0da9d947a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be loaded from data/picked_pictures.npy\n",
      "Constructing attribute data\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "X, Y = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tLeNjGAu0D9-",
    "outputId": "1469f3b8-7e3d-482e-b3d8-77382bb87a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14993, 23), (14993,)]\n",
      "(14993,)\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in X])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP5N-nfKvt1v"
   },
   "outputs": [],
   "source": [
    "def shuffle(X, Y):\n",
    "    idxs = list(range(len(Y)))\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i][idxs]\n",
    "    else:\n",
    "        X = X[idxs]\n",
    "\n",
    "    Y = Y[idxs]\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def split(X, Y, s=0.2):\n",
    "    s = int(s * len(Y))\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        X_train = [x[:-s] for x in X]\n",
    "        X_test = [x[-s:] for x in X]\n",
    "    else:\n",
    "        X_train = X[:-s]\n",
    "        X_test = X[-s:]\n",
    "\n",
    "    Y_train = Y[:-s]\n",
    "    Y_test = Y[-s:]\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "\n",
    "def convert_for_all(X, Y):\n",
    "    # For single image training, make a datapoint for each image or the default zero image\n",
    "    Xs = [[], []]\n",
    "    Ys = []\n",
    "    for i in range(len(X[1])):\n",
    "        if len(X[1][i]) == 0:\n",
    "            Xs[0].append(X[0][i])\n",
    "            Xs[1].append(np.zeros((64, 64, 3)))\n",
    "            Ys.append(Y[i])\n",
    "        else:\n",
    "            # Make a datapoint for all images. We assume equal relevance of images\n",
    "            for img in X[1][i]:\n",
    "                if img.shape != (64, 64, 3):\n",
    "                    # Convert to RGB (not a common occurence)\n",
    "                    img = np.array([[[x, x, x] for x in row] for row in img])\n",
    "                \n",
    "                Xs[0].append(X[0][i])\n",
    "                Xs[1].append(img)\n",
    "                Ys.append(Y[i])\n",
    "                \n",
    "    print('Extracted', len(Y), 'datapoints')\n",
    "\n",
    "    X = [\n",
    "        np.array(Xs[0]),\n",
    "        np.array(Xs[1])\n",
    "    ]\n",
    "    Y = np.array(Ys)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def convert_for_poly(X, Y):\n",
    "    # Find the max image count\n",
    "    ct = max(len(x) for x in X[1])\n",
    "    \n",
    "    # Apply the base allocations\n",
    "    Xs = [\n",
    "        X[0],\n",
    "        np.zeros((len(X[1]), ct, 64, 64, 3))\n",
    "    ]\n",
    "    \n",
    "    # Insert the images\n",
    "    for i, x in enumerate(X[1]):\n",
    "        if len(x) > 0:\n",
    "            Xs[i,:len(x)] = x\n",
    "    \n",
    "    return Xs, Y\n",
    "    \n",
    "\n",
    "def convert_for_single_axis(X, Y, ax=0):\n",
    "    return X[ax], Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkUUG-buDZ5z"
   },
   "outputs": [],
   "source": [
    "X, Y = shuffle(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsCyyd2Fvt1x"
   },
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlttRuokSCOj"
   },
   "outputs": [],
   "source": [
    "def reg_loss(t, y):\n",
    "    print('t:', t)\n",
    "    print('y:', y)\n",
    "    \n",
    "    a = (35./6)*t**4 - (4./3)*t**3 + (29./12)*t**2 - (20./3)*t\n",
    "    b = -.875*t**4 + (8 + 1./12)*t**3 + 9.125*t**2 + (95./12)*t + 1\n",
    "    \n",
    "    c = (a + b) / 2\n",
    "    d = c - a\n",
    "    return K.relu(K.abs(y - c) - d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKtOpAxGvt1y"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "\n",
    "class KaggleModel:\n",
    "    def __init__(self, model, train, test):\n",
    "        model.summary()\n",
    "        self.model = model\n",
    "        self.train_data = train\n",
    "        self.test_data = test\n",
    "        \n",
    "        self.compiled = False\n",
    "\n",
    "    def compile(self, optimizer='adam'):\n",
    "        \"\"\" Compiles the model. Should be defined by the user.\n",
    "        \"\"\"\n",
    "        if not self.compiled:\n",
    "            print('Compiling', self.model.name)\n",
    "            self.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            self.compiled = True\n",
    "\n",
    "    def train(self, epochs=1):\n",
    "        \"\"\" Default training behavior. Simply does a Model.fit(X, Y).\n",
    "        \"\"\"\n",
    "        # Get the training data\n",
    "        X_train, Y_train = self.train_data\n",
    "\n",
    "        checkpoint = ModelCheckpoint('model.h5')\n",
    "        \n",
    "        # Fit to the data\n",
    "        history = self.model.fit(X_train, Y_train, epochs=epochs, validation_data=self.test_data, callbacks=[checkpoint])\n",
    "        if 'val_acc' in history.history:\n",
    "            self.val_acc = history.history['val_acc'][-1]\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "def ResidualBlock(mdl):\n",
    "    x = Input(shape=mdl.input_shape[1:])\n",
    "\n",
    "    y = mdl(x)\n",
    "    y = Add()([x, y])\n",
    "\n",
    "    return Model(x, y)\n",
    "        \n",
    "class OheModel(KaggleModel):\n",
    "    def __init__(self, train, test):\n",
    "        kernel = Sequential(name='image_free_encoder')\n",
    "        \n",
    "        x = Input(shape=(len(numeric_cols) + len(one_hot_cols) + 3,))\n",
    "        \n",
    "        # Get the numerics\n",
    "        z = Lambda(lambda z: z[:,:-len(one_hot_cols)])(x)\n",
    "        \n",
    "        \"\"\"\n",
    "        z = Dense(64)(z)\n",
    "        z = BatchNormalization()(z)\n",
    "        z = Activation('relu')(z)\n",
    "        \"\"\"\n",
    "        \n",
    "        ys = [z]\n",
    "        \n",
    "        # Split up the encodings\n",
    "        i = len(numeric_cols) + 3 + len(one_hot_cols) - 1\n",
    "        for k in one_hot_cols:\n",
    "            y = Lambda(lambda z: z[:,i:i+1])(x)\n",
    "            y = Embedding(one_hot_cols[k], math.ceil(math.sqrt(one_hot_cols[k])))(y)\n",
    "            y = Flatten()(y)\n",
    "            ys.append(y)\n",
    "            i -= 1\n",
    "        \n",
    "        y = Concatenate()(ys)\n",
    "        \n",
    "        kernel.add(Model(x, y))\n",
    "        kernel.add(BatchNormalization())\n",
    "        \n",
    "        kernel.add(Dropout(0.3))\n",
    "        kernel.add(Dense(128))\n",
    "        kernel.add(BatchNormalization())\n",
    "        kernel.add(Activation('relu'))\n",
    "\n",
    "        model = Sequential(name='image_free')\n",
    "        model.add(kernel)\n",
    "        \n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(64))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        # Labels are one of [0, 1, 2, 3, 4]\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        # Build using the built model\n",
    "        super().__init__(model, train, test)\n",
    "                \n",
    "class RegModel(KaggleModel):\n",
    "    def __init__(self, train, test):\n",
    "        kernel = Sequential(name='image_free_encoder')\n",
    "        \n",
    "        x = Input(shape=(len(numeric_cols) + len(one_hot_cols) + 3,))\n",
    "        \n",
    "        # Get the numerics\n",
    "        z = Lambda(lambda z: z[:,:-len(one_hot_cols)])(x)\n",
    "        \n",
    "        ys = [z]\n",
    "        \n",
    "        # Split up the encodings\n",
    "        i = len(numeric_cols) + 3 + len(one_hot_cols) - 1\n",
    "        for k in one_hot_cols:\n",
    "            y = Lambda(lambda z: z[:,i:i+1])(x)\n",
    "            y = Embedding(one_hot_cols[k], math.ceil(math.sqrt(one_hot_cols[k])))(y)\n",
    "            y = Flatten()(y)\n",
    "            ys.append(y)\n",
    "            i -= 1\n",
    "        \n",
    "        y = Concatenate()(ys)\n",
    "        \n",
    "        kernel.add(Model(x, y))\n",
    "        \n",
    "        kernel.add(BatchNormalization())\n",
    "        \n",
    "        kernel.add(Dropout(0.3))\n",
    "        kernel.add(Dense(128))\n",
    "        kernel.add(BatchNormalization())\n",
    "        kernel.add(Activation('relu'))\n",
    "\n",
    "        model = Sequential(name='image_free')\n",
    "        model.add(kernel)\n",
    "        \n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(64))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "        # Labels are one of [0, 1, 2, 3, 4]\n",
    "        model.add(Dense(1, activation='relu'))\n",
    "\n",
    "        # Build using the built model\n",
    "        super().__init__(model, train, test)\n",
    "        \n",
    "    def compile(self, optimizer='adam'):\n",
    "        \"\"\" Compiles the model. Should be defined by the user.\n",
    "        \"\"\"\n",
    "        if not self.compiled:\n",
    "            print('Compiling', self.model.name)\n",
    "            self.model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['acc'])\n",
    "            self.compiled = True\n",
    "\n",
    "class SingleImageModel(KaggleModel):\n",
    "    def __init__(self, train, test):\n",
    "        # The model takes in attributes and an image.\n",
    "        \n",
    "        kernel = SingleImageModel.make_kernel()\n",
    "        kernel.summary()\n",
    "\n",
    "        model = Sequential(name='single_image')\n",
    "\n",
    "        model.add(kernel)\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        super().__init__(model, train, test)\n",
    "    \n",
    "    def make_kernel():\n",
    "        kernel = Sequential(name='single_image_encoder')\n",
    "        \n",
    "        # Architecture for the images\n",
    "        f = 64\n",
    "        kernel.add(Conv2D(f, kernel_size=(7,7), strides=(1,1), padding='same', input_shape=(64, 64, 3)))\n",
    "        kernel.add(BatchNormalization())\n",
    "\n",
    "        while kernel.output_shape[1] > 4:\n",
    "            for _ in range(2):\n",
    "                # Old output is kept as residue\n",
    "                x = z = Input(shape=(kernel.output_shape[1:]))\n",
    "\n",
    "                for _ in range(2):\n",
    "                    z = Activation('relu')(z)\n",
    "                    z = Dropout(0.5)(z)\n",
    "                    z = Conv2D(f, kernel_size=(5,5), strides=(1,1), padding='same')(z)\n",
    "                    z = BatchNormalization()(z)\n",
    "                \n",
    "                # The sum of the residue and the new computation\n",
    "                y = Add()([x, z])\n",
    "                \n",
    "                # Add the residual block\n",
    "                blk = Model(x, y)\n",
    "                kernel.add(blk)\n",
    "            \n",
    "            # Reduce dimension\n",
    "            kernel.add(MaxPooling2D((2,2)))\n",
    "            #f *= 2\n",
    "            kernel.add(Conv2D(f, kernel_size=(1,1), strides=(1,1), padding='same', input_shape=(64, 64, 3)))\n",
    "        \n",
    "        \n",
    "        kernel.add(Flatten())\n",
    "        \n",
    "        kernel.add(Dropout(0.5))\n",
    "        kernel.add(Dense(128))\n",
    "        kernel.add(BatchNormalization())\n",
    "        kernel.add(Activation('relu'))\n",
    "        \n",
    "        return kernel\n",
    "\n",
    "class UnionModel(KaggleModel):\n",
    "    def __init__(self, models, train, test, freeze=True):\n",
    "        \n",
    "        xs = []\n",
    "        ys = []\n",
    "        for model in models:\n",
    "            model = model.model\n",
    "            x = Input(shape=model.input_shape[1:], name='{}_in'.format(model.name))\n",
    "            # Get the first layer of the model. This is the encoder\n",
    "            layer = model.get_layer(index=0)\n",
    "            \n",
    "            # It must not be trainable\n",
    "            if freeze: layer.trainable = False\n",
    "            # The output only utilizes the encoder component\n",
    "            y = layer(x)\n",
    "            \n",
    "            # Output should be flat\n",
    "            if len(y.shape) > 2:\n",
    "                y = Flatten()(y)\n",
    "                \n",
    "            # Save values\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "        y = Concatenate()(ys)\n",
    "\n",
    "        y = Dense(128)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Dense(5, activation='softmax')(y)\n",
    "        \n",
    "        model = Model(xs, y)\n",
    "\n",
    "        super().__init__(model, train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAdsnP0vyZRd"
   },
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "\n",
    "class VggModel(KaggleModel):\n",
    "    def __init__(self, train, test):\n",
    "        vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "        vgg.trainable = False\n",
    "        self.vgg = vgg\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(vgg)\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        super().__init__(model, train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_PikPOd3GRs"
   },
   "outputs": [],
   "source": [
    "class PolyImageModel(KaggleModel):\n",
    "    def __init__(self, train, test, kernel=None):\n",
    "        if kernel is None:\n",
    "            kernel = SingleImageModel.make_kernel()\n",
    "            \n",
    "        knl = Sequential()\n",
    "        \n",
    "        # Compute the kernel output\n",
    "        knl.add(TimeDistributed(kernel, input_shape=(None, 64, 64, 3)))\n",
    "        knl.add(GlobalAveragePooling1D())\n",
    "        knl.summary()\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(knl)\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        super().__init__(model, train, test)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcePWPI9vt11"
   },
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TGnFj8Wvt12"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "def train_model(mdl, X, Y, epochs=32, return_history=False, use_cat_out=True):\n",
    "    # Shuffle the data\n",
    "    shuffle(X, Y)\n",
    "\n",
    "    # One hot encode the output\n",
    "    if use_cat_out:\n",
    "        Y = to_categorical(Y)\n",
    "\n",
    "    # Validation split\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = split(X, Y)\n",
    "\n",
    "    print('Training points:', len(Y_train))\n",
    "    print('Validation points:', len(Y_valid))\n",
    "    print('Total points:', len(Y))\n",
    "\n",
    "    clf = mdl((X_train, Y_train), (X_valid, Y_valid))\n",
    "\n",
    "    # Build the model\n",
    "    clf.compile(optimizer=Adam(lr=2e-4))\n",
    "\n",
    "    # Fit to the data\n",
    "    history = clf.train(epochs=epochs)\n",
    "\n",
    "    if return_history:\n",
    "        return clf, history\n",
    "    else:\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9L8-hyo8vt14"
   },
   "source": [
    "### Model Training\n",
    "\n",
    "Models are trained one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwifiFbc86tj"
   },
   "source": [
    "#### Attribute-Only Model\n",
    "\n",
    "We seek to train a model to train exclusively on the numerical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4087
    },
    "colab_type": "code",
    "id": "If7ipuTJPAd8",
    "outputId": "e3c48b10-a9c5-44cd-dad3-75948c3cbd1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training points: 11995\n",
      "Validation points: 2998\n",
      "Total points: 14993\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_free_encoder (Sequenti (None, 128)               21638     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 30,475\n",
      "Trainable params: 29,943\n",
      "Non-trainable params: 532\n",
      "_________________________________________________________________\n",
      "Compiling image_free\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11995 samples, validate on 2998 samples\n",
      "Epoch 1/96\n",
      "11995/11995 [==============================] - 9s 734us/step - loss: 1.6760 - acc: 0.2484 - val_loss: 1.5109 - val_acc: 0.2698\n",
      "Epoch 2/96\n",
      "11995/11995 [==============================] - 6s 461us/step - loss: 1.5645 - acc: 0.2744 - val_loss: 1.4736 - val_acc: 0.2862\n",
      "Epoch 3/96\n",
      "11995/11995 [==============================] - 5s 435us/step - loss: 1.5247 - acc: 0.2728 - val_loss: 1.4674 - val_acc: 0.2929\n",
      "Epoch 4/96\n",
      "11995/11995 [==============================] - 4s 374us/step - loss: 1.5133 - acc: 0.2803 - val_loss: 1.4658 - val_acc: 0.2895\n",
      "Epoch 5/96\n",
      "11995/11995 [==============================] - 5s 417us/step - loss: 1.5011 - acc: 0.2802 - val_loss: 1.4597 - val_acc: 0.2882\n",
      "Epoch 6/96\n",
      "11995/11995 [==============================] - 5s 423us/step - loss: 1.4913 - acc: 0.2826 - val_loss: 1.4543 - val_acc: 0.2979\n",
      "Epoch 7/96\n",
      "11995/11995 [==============================] - 5s 439us/step - loss: 1.4895 - acc: 0.2840 - val_loss: 1.4522 - val_acc: 0.3082\n",
      "Epoch 8/96\n",
      "11995/11995 [==============================] - 5s 417us/step - loss: 1.4801 - acc: 0.2900 - val_loss: 1.4503 - val_acc: 0.3065\n",
      "Epoch 9/96\n",
      "11995/11995 [==============================] - 5s 439us/step - loss: 1.4781 - acc: 0.2870 - val_loss: 1.4485 - val_acc: 0.3112\n",
      "Epoch 10/96\n",
      "11995/11995 [==============================] - 5s 386us/step - loss: 1.4765 - acc: 0.2936 - val_loss: 1.4488 - val_acc: 0.3129\n",
      "Epoch 11/96\n",
      "11995/11995 [==============================] - 5s 382us/step - loss: 1.4724 - acc: 0.2880 - val_loss: 1.4482 - val_acc: 0.3092\n",
      "Epoch 12/96\n",
      "11995/11995 [==============================] - 5s 450us/step - loss: 1.4718 - acc: 0.3019 - val_loss: 1.4479 - val_acc: 0.3115\n",
      "Epoch 13/96\n",
      "11995/11995 [==============================] - 5s 399us/step - loss: 1.4660 - acc: 0.3020 - val_loss: 1.4464 - val_acc: 0.3079\n",
      "Epoch 14/96\n",
      "11995/11995 [==============================] - 5s 385us/step - loss: 1.4658 - acc: 0.2963 - val_loss: 1.4459 - val_acc: 0.3062\n",
      "Epoch 15/96\n",
      "11995/11995 [==============================] - 5s 459us/step - loss: 1.4652 - acc: 0.3037 - val_loss: 1.4451 - val_acc: 0.3102\n",
      "Epoch 16/96\n",
      "11995/11995 [==============================] - 5s 420us/step - loss: 1.4590 - acc: 0.3079 - val_loss: 1.4452 - val_acc: 0.3139\n",
      "Epoch 17/96\n",
      "11995/11995 [==============================] - 5s 381us/step - loss: 1.4619 - acc: 0.3057 - val_loss: 1.4457 - val_acc: 0.3105\n",
      "Epoch 18/96\n",
      "11995/11995 [==============================] - 6s 462us/step - loss: 1.4629 - acc: 0.3014 - val_loss: 1.4434 - val_acc: 0.3002\n",
      "Epoch 19/96\n",
      "11995/11995 [==============================] - 5s 388us/step - loss: 1.4563 - acc: 0.3115 - val_loss: 1.4424 - val_acc: 0.3145\n",
      "Epoch 20/96\n",
      "11995/11995 [==============================] - 6s 460us/step - loss: 1.4581 - acc: 0.3134 - val_loss: 1.4412 - val_acc: 0.3169\n",
      "Epoch 21/96\n",
      "11995/11995 [==============================] - 5s 421us/step - loss: 1.4564 - acc: 0.3113 - val_loss: 1.4416 - val_acc: 0.3229\n",
      "Epoch 22/96\n",
      "11995/11995 [==============================] - 5s 432us/step - loss: 1.4565 - acc: 0.3120 - val_loss: 1.4400 - val_acc: 0.3262\n",
      "Epoch 23/96\n",
      "11995/11995 [==============================] - 6s 513us/step - loss: 1.4529 - acc: 0.3043 - val_loss: 1.4406 - val_acc: 0.3185\n",
      "Epoch 24/96\n",
      "11995/11995 [==============================] - 5s 384us/step - loss: 1.4519 - acc: 0.3117 - val_loss: 1.4375 - val_acc: 0.3219\n",
      "Epoch 25/96\n",
      "11995/11995 [==============================] - 5s 380us/step - loss: 1.4516 - acc: 0.3145 - val_loss: 1.4366 - val_acc: 0.3326\n",
      "Epoch 26/96\n",
      "11995/11995 [==============================] - 6s 478us/step - loss: 1.4511 - acc: 0.3179 - val_loss: 1.4354 - val_acc: 0.3296\n",
      "Epoch 27/96\n",
      "11995/11995 [==============================] - 5s 380us/step - loss: 1.4531 - acc: 0.3100 - val_loss: 1.4356 - val_acc: 0.3239\n",
      "Epoch 28/96\n",
      "11995/11995 [==============================] - 6s 495us/step - loss: 1.4478 - acc: 0.3126 - val_loss: 1.4359 - val_acc: 0.3239\n",
      "Epoch 29/96\n",
      "11995/11995 [==============================] - 5s 383us/step - loss: 1.4488 - acc: 0.3216 - val_loss: 1.4353 - val_acc: 0.3219\n",
      "Epoch 30/96\n",
      "11995/11995 [==============================] - 6s 499us/step - loss: 1.4454 - acc: 0.3224 - val_loss: 1.4338 - val_acc: 0.3249\n",
      "Epoch 31/96\n",
      "11995/11995 [==============================] - 5s 384us/step - loss: 1.4460 - acc: 0.3241 - val_loss: 1.4341 - val_acc: 0.3215\n",
      "Epoch 32/96\n",
      "11995/11995 [==============================] - 5s 384us/step - loss: 1.4480 - acc: 0.3174 - val_loss: 1.4338 - val_acc: 0.3222\n",
      "Epoch 33/96\n",
      "11995/11995 [==============================] - 5s 452us/step - loss: 1.4444 - acc: 0.3239 - val_loss: 1.4317 - val_acc: 0.3272\n",
      "Epoch 34/96\n",
      "11995/11995 [==============================] - 5s 384us/step - loss: 1.4478 - acc: 0.3155 - val_loss: 1.4331 - val_acc: 0.3239\n",
      "Epoch 35/96\n",
      "11995/11995 [==============================] - 6s 483us/step - loss: 1.4416 - acc: 0.3284 - val_loss: 1.4334 - val_acc: 0.3222\n",
      "Epoch 36/96\n",
      "11995/11995 [==============================] - 5s 430us/step - loss: 1.4437 - acc: 0.3220 - val_loss: 1.4295 - val_acc: 0.3309\n",
      "Epoch 37/96\n",
      "11995/11995 [==============================] - 5s 429us/step - loss: 1.4405 - acc: 0.3261 - val_loss: 1.4289 - val_acc: 0.3342\n",
      "Epoch 38/96\n",
      "11995/11995 [==============================] - 6s 507us/step - loss: 1.4423 - acc: 0.3271 - val_loss: 1.4295 - val_acc: 0.3319\n",
      "Epoch 39/96\n",
      "11995/11995 [==============================] - 4s 374us/step - loss: 1.4438 - acc: 0.3203 - val_loss: 1.4292 - val_acc: 0.3252\n",
      "Epoch 40/96\n",
      "11995/11995 [==============================] - 6s 508us/step - loss: 1.4392 - acc: 0.3327 - val_loss: 1.4289 - val_acc: 0.3286\n",
      "Epoch 41/96\n",
      "11995/11995 [==============================] - 4s 372us/step - loss: 1.4413 - acc: 0.3301 - val_loss: 1.4265 - val_acc: 0.3376\n",
      "Epoch 42/96\n",
      "11995/11995 [==============================] - 5s 446us/step - loss: 1.4383 - acc: 0.3280 - val_loss: 1.4268 - val_acc: 0.3369\n",
      "Epoch 43/96\n",
      "11995/11995 [==============================] - 4s 375us/step - loss: 1.4383 - acc: 0.3247 - val_loss: 1.4265 - val_acc: 0.3279\n",
      "Epoch 44/96\n",
      "11995/11995 [==============================] - 6s 486us/step - loss: 1.4392 - acc: 0.3293 - val_loss: 1.4260 - val_acc: 0.3389\n",
      "Epoch 45/96\n",
      "11995/11995 [==============================] - 4s 374us/step - loss: 1.4381 - acc: 0.3287 - val_loss: 1.4261 - val_acc: 0.3326\n",
      "Epoch 46/96\n",
      "11995/11995 [==============================] - 5s 421us/step - loss: 1.4402 - acc: 0.3261 - val_loss: 1.4257 - val_acc: 0.3399\n",
      "Epoch 47/96\n",
      "11995/11995 [==============================] - 4s 375us/step - loss: 1.4383 - acc: 0.3260 - val_loss: 1.4259 - val_acc: 0.3399\n",
      "Epoch 48/96\n",
      "11995/11995 [==============================] - 4s 375us/step - loss: 1.4396 - acc: 0.3252 - val_loss: 1.4251 - val_acc: 0.3366\n",
      "Epoch 49/96\n",
      "11995/11995 [==============================] - 6s 509us/step - loss: 1.4383 - acc: 0.3263 - val_loss: 1.4257 - val_acc: 0.3409\n",
      "Epoch 50/96\n",
      "11995/11995 [==============================] - 5s 388us/step - loss: 1.4375 - acc: 0.3332 - val_loss: 1.4249 - val_acc: 0.3419\n",
      "Epoch 51/96\n",
      "11995/11995 [==============================] - 5s 418us/step - loss: 1.4390 - acc: 0.3310 - val_loss: 1.4249 - val_acc: 0.3432\n",
      "Epoch 52/96\n",
      "11995/11995 [==============================] - 8s 628us/step - loss: 1.4368 - acc: 0.3276 - val_loss: 1.4256 - val_acc: 0.3339\n",
      "Epoch 53/96\n",
      "11995/11995 [==============================] - 5s 391us/step - loss: 1.4324 - acc: 0.3413 - val_loss: 1.4248 - val_acc: 0.3372\n",
      "Epoch 54/96\n",
      "11995/11995 [==============================] - 6s 482us/step - loss: 1.4337 - acc: 0.3308 - val_loss: 1.4238 - val_acc: 0.3369\n",
      "Epoch 55/96\n",
      "11995/11995 [==============================] - 5s 395us/step - loss: 1.4323 - acc: 0.3400 - val_loss: 1.4231 - val_acc: 0.3379\n",
      "Epoch 56/96\n",
      "11995/11995 [==============================] - 6s 502us/step - loss: 1.4390 - acc: 0.3292 - val_loss: 1.4225 - val_acc: 0.3419\n",
      "Epoch 57/96\n",
      "11995/11995 [==============================] - 5s 416us/step - loss: 1.4331 - acc: 0.3351 - val_loss: 1.4224 - val_acc: 0.3416\n",
      "Epoch 58/96\n",
      "11995/11995 [==============================] - 7s 567us/step - loss: 1.4340 - acc: 0.3361 - val_loss: 1.4219 - val_acc: 0.3459\n",
      "Epoch 59/96\n",
      "11995/11995 [==============================] - 5s 382us/step - loss: 1.4324 - acc: 0.3384 - val_loss: 1.4224 - val_acc: 0.3439\n",
      "Epoch 60/96\n",
      "11995/11995 [==============================] - 5s 416us/step - loss: 1.4335 - acc: 0.3309 - val_loss: 1.4220 - val_acc: 0.3419\n",
      "Epoch 61/96\n",
      "11995/11995 [==============================] - 5s 406us/step - loss: 1.4368 - acc: 0.3312 - val_loss: 1.4245 - val_acc: 0.3426\n",
      "Epoch 62/96\n",
      "11995/11995 [==============================] - 5s 453us/step - loss: 1.4352 - acc: 0.3268 - val_loss: 1.4233 - val_acc: 0.3416\n",
      "Epoch 63/96\n",
      "11995/11995 [==============================] - 5s 405us/step - loss: 1.4361 - acc: 0.3282 - val_loss: 1.4240 - val_acc: 0.3469\n",
      "Epoch 64/96\n",
      "11995/11995 [==============================] - 6s 505us/step - loss: 1.4345 - acc: 0.3326 - val_loss: 1.4235 - val_acc: 0.3442\n",
      "Epoch 65/96\n",
      "11995/11995 [==============================] - 5s 381us/step - loss: 1.4295 - acc: 0.3386 - val_loss: 1.4218 - val_acc: 0.3476\n",
      "Epoch 66/96\n",
      "11995/11995 [==============================] - 5s 387us/step - loss: 1.4320 - acc: 0.3361 - val_loss: 1.4200 - val_acc: 0.3456\n",
      "Epoch 67/96\n",
      "11995/11995 [==============================] - 5s 378us/step - loss: 1.4350 - acc: 0.3348 - val_loss: 1.4210 - val_acc: 0.3436\n",
      "Epoch 68/96\n",
      "11995/11995 [==============================] - 5s 407us/step - loss: 1.4371 - acc: 0.3336 - val_loss: 1.4213 - val_acc: 0.3456\n",
      "Epoch 69/96\n",
      "11995/11995 [==============================] - 5s 384us/step - loss: 1.4318 - acc: 0.3317 - val_loss: 1.4210 - val_acc: 0.3522\n",
      "Epoch 70/96\n",
      "11995/11995 [==============================] - 5s 386us/step - loss: 1.4343 - acc: 0.3325 - val_loss: 1.4209 - val_acc: 0.3496\n",
      "Epoch 71/96\n",
      "11995/11995 [==============================] - 6s 535us/step - loss: 1.4314 - acc: 0.3375 - val_loss: 1.4194 - val_acc: 0.3479\n",
      "Epoch 72/96\n",
      "11995/11995 [==============================] - 5s 382us/step - loss: 1.4326 - acc: 0.3391 - val_loss: 1.4203 - val_acc: 0.3479\n",
      "Epoch 73/96\n",
      "11995/11995 [==============================] - 5s 399us/step - loss: 1.4324 - acc: 0.3359 - val_loss: 1.4207 - val_acc: 0.3519\n",
      "Epoch 74/96\n",
      "11995/11995 [==============================] - 5s 380us/step - loss: 1.4273 - acc: 0.3406 - val_loss: 1.4203 - val_acc: 0.3422\n",
      "Epoch 75/96\n",
      "11995/11995 [==============================] - 5s 397us/step - loss: 1.4309 - acc: 0.3381 - val_loss: 1.4210 - val_acc: 0.3462\n",
      "Epoch 76/96\n",
      "11995/11995 [==============================] - 5s 413us/step - loss: 1.4288 - acc: 0.3394 - val_loss: 1.4203 - val_acc: 0.3459\n",
      "Epoch 77/96\n",
      "11995/11995 [==============================] - 5s 458us/step - loss: 1.4284 - acc: 0.3400 - val_loss: 1.4191 - val_acc: 0.3499\n",
      "Epoch 78/96\n",
      "11995/11995 [==============================] - 5s 381us/step - loss: 1.4266 - acc: 0.3456 - val_loss: 1.4188 - val_acc: 0.3459\n",
      "Epoch 79/96\n",
      "11995/11995 [==============================] - 5s 382us/step - loss: 1.4314 - acc: 0.3387 - val_loss: 1.4189 - val_acc: 0.3449\n",
      "Epoch 80/96\n",
      "11995/11995 [==============================] - 5s 391us/step - loss: 1.4307 - acc: 0.3425 - val_loss: 1.4185 - val_acc: 0.3466\n",
      "Epoch 81/96\n",
      "11995/11995 [==============================] - 5s 409us/step - loss: 1.4324 - acc: 0.3378 - val_loss: 1.4202 - val_acc: 0.3419\n",
      "Epoch 82/96\n",
      "11995/11995 [==============================] - 5s 391us/step - loss: 1.4335 - acc: 0.3361 - val_loss: 1.4204 - val_acc: 0.3432\n",
      "Epoch 83/96\n",
      "11995/11995 [==============================] - 5s 409us/step - loss: 1.4280 - acc: 0.3422 - val_loss: 1.4186 - val_acc: 0.3469\n",
      "Epoch 84/96\n",
      "11995/11995 [==============================] - 5s 393us/step - loss: 1.4287 - acc: 0.3426 - val_loss: 1.4207 - val_acc: 0.3382\n",
      "Epoch 85/96\n",
      "11995/11995 [==============================] - 5s 393us/step - loss: 1.4302 - acc: 0.3420 - val_loss: 1.4205 - val_acc: 0.3376\n",
      "Epoch 86/96\n",
      "11995/11995 [==============================] - 5s 391us/step - loss: 1.4273 - acc: 0.3444 - val_loss: 1.4182 - val_acc: 0.3466\n",
      "Epoch 87/96\n",
      "11995/11995 [==============================] - 5s 386us/step - loss: 1.4282 - acc: 0.3376 - val_loss: 1.4169 - val_acc: 0.3479\n",
      "Epoch 88/96\n",
      "11995/11995 [==============================] - 5s 423us/step - loss: 1.4258 - acc: 0.3412 - val_loss: 1.4189 - val_acc: 0.3402\n",
      "Epoch 89/96\n",
      "11995/11995 [==============================] - 5s 445us/step - loss: 1.4298 - acc: 0.3371 - val_loss: 1.4173 - val_acc: 0.3436\n",
      "Epoch 90/96\n",
      "11995/11995 [==============================] - 5s 389us/step - loss: 1.4286 - acc: 0.3369 - val_loss: 1.4178 - val_acc: 0.3489\n",
      "Epoch 91/96\n",
      "11995/11995 [==============================] - 7s 543us/step - loss: 1.4296 - acc: 0.3395 - val_loss: 1.4186 - val_acc: 0.3489\n",
      "Epoch 92/96\n",
      "11995/11995 [==============================] - 5s 389us/step - loss: 1.4305 - acc: 0.3401 - val_loss: 1.4176 - val_acc: 0.3516\n",
      "Epoch 93/96\n",
      "11995/11995 [==============================] - 5s 387us/step - loss: 1.4263 - acc: 0.3390 - val_loss: 1.4183 - val_acc: 0.3469\n",
      "Epoch 94/96\n",
      "11995/11995 [==============================] - 5s 389us/step - loss: 1.4245 - acc: 0.3495 - val_loss: 1.4179 - val_acc: 0.3492\n",
      "Epoch 95/96\n",
      "11995/11995 [==============================] - 5s 389us/step - loss: 1.4277 - acc: 0.3456 - val_loss: 1.4163 - val_acc: 0.3509\n",
      "Epoch 96/96\n",
      "11995/11995 [==============================] - 6s 533us/step - loss: 1.4258 - acc: 0.3436 - val_loss: 1.4178 - val_acc: 0.3476\n"
     ]
    }
   ],
   "source": [
    "# Attribute model data\n",
    "X_attr, Y_attr = convert_for_single_axis(X, Y, ax=0)\n",
    "\n",
    "# Image-free model\n",
    "attr_clf = OheModel\n",
    "\n",
    "# Train the model\n",
    "attr_clf, history = train_model(attr_clf, X_attr, Y_attr, epochs=96, return_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vcyeSoDEaCMN"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "SVG(model_to_dot(attr_clf.model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model(\n",
    "    model=attr_clf.model, show_shapes=False,\n",
    "    to_file=f'attr_clf.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "jTdTdN35QPTr",
    "outputId": "9c84eb52-35e7-4dc9-ab0e-5cd29b7bd088"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRlRMLAzDMIyomFgYhmEYUfl/jOwWmrwDF+MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iWSb7bLPKKWr",
    "outputId": "880217a8-5fd1-4632-ddd3-b0f66868bc38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.11352593396592947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "X_valid, Y_valid = attr_clf.test_data\n",
    "\n",
    "Y_pred = attr_clf.predict(X_valid)\n",
    "\n",
    "# Convert to numeric labels\n",
    "Y_valid = np.argmax(Y_valid, -1)\n",
    "Y_pred = np.argmax(Y_pred, -1)\n",
    "\n",
    "print('Kappa:', cohen_kappa_score(Y_valid, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IL41anIOpbkB"
   },
   "source": [
    "#### Regression Attribute-only Model\n",
    "\n",
    "We will try using regression techniques to better utilize the structure of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3726
    },
    "colab_type": "code",
    "id": "pwXvNyuIUElS",
    "outputId": "d864bdca-15ee-417a-a332-46a2e91bd1ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training points: 11995\n",
      "Validation points: 2998\n",
      "Total points: 14993\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_free_encoder (Sequenti (None, 128)               21638     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 30,215\n",
      "Trainable params: 29,683\n",
      "Non-trainable params: 532\n",
      "_________________________________________________________________\n",
      "Compiling image_free\n",
      "Train on 11995 samples, validate on 2998 samples\n",
      "Epoch 1/96\n",
      "11995/11995 [==============================] - 7s 607us/step - loss: 2.4609 - acc: 0.2368 - val_loss: 1.3961 - val_acc: 0.2535\n",
      "Epoch 2/96\n",
      "11995/11995 [==============================] - 4s 370us/step - loss: 1.3965 - acc: 0.2567 - val_loss: 1.3743 - val_acc: 0.2402\n",
      "Epoch 3/96\n",
      "11995/11995 [==============================] - 4s 353us/step - loss: 1.3767 - acc: 0.2532 - val_loss: 1.3693 - val_acc: 0.2368\n",
      "Epoch 4/96\n",
      "11995/11995 [==============================] - 4s 353us/step - loss: 1.3730 - acc: 0.2502 - val_loss: 1.3687 - val_acc: 0.2332\n",
      "Epoch 5/96\n",
      "11995/11995 [==============================] - 4s 356us/step - loss: 1.3651 - acc: 0.2526 - val_loss: 1.3690 - val_acc: 0.2348\n",
      "Epoch 6/96\n",
      "11995/11995 [==============================] - 4s 374us/step - loss: 1.3699 - acc: 0.2514 - val_loss: 1.3666 - val_acc: 0.2385\n",
      "Epoch 7/96\n",
      "11995/11995 [==============================] - 4s 354us/step - loss: 1.3634 - acc: 0.2515 - val_loss: 1.3664 - val_acc: 0.2378\n",
      "Epoch 8/96\n",
      "11995/11995 [==============================] - 5s 408us/step - loss: 1.3652 - acc: 0.2518 - val_loss: 1.3613 - val_acc: 0.2418\n",
      "Epoch 9/96\n",
      "11995/11995 [==============================] - 4s 350us/step - loss: 1.3667 - acc: 0.2514 - val_loss: 1.3637 - val_acc: 0.2318\n",
      "Epoch 10/96\n",
      "11995/11995 [==============================] - 5s 414us/step - loss: 1.3672 - acc: 0.2481 - val_loss: 1.3568 - val_acc: 0.2515\n",
      "Epoch 11/96\n",
      "11995/11995 [==============================] - 5s 376us/step - loss: 1.3579 - acc: 0.2525 - val_loss: 1.3578 - val_acc: 0.2462\n",
      "Epoch 12/96\n",
      "11995/11995 [==============================] - 4s 359us/step - loss: 1.3606 - acc: 0.2547 - val_loss: 1.3600 - val_acc: 0.2315\n",
      "Epoch 13/96\n",
      "11995/11995 [==============================] - 6s 531us/step - loss: 1.3561 - acc: 0.2531 - val_loss: 1.3593 - val_acc: 0.2375\n",
      "Epoch 14/96\n",
      "11995/11995 [==============================] - 4s 355us/step - loss: 1.3609 - acc: 0.2508 - val_loss: 1.3646 - val_acc: 0.2282\n",
      "Epoch 15/96\n",
      "11995/11995 [==============================] - 4s 351us/step - loss: 1.3554 - acc: 0.2544 - val_loss: 1.3528 - val_acc: 0.2418\n",
      "Epoch 16/96\n",
      "11995/11995 [==============================] - 6s 515us/step - loss: 1.3589 - acc: 0.2514 - val_loss: 1.3637 - val_acc: 0.2328\n",
      "Epoch 17/96\n",
      "11995/11995 [==============================] - 4s 354us/step - loss: 1.3569 - acc: 0.2506 - val_loss: 1.3602 - val_acc: 0.2345\n",
      "Epoch 18/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3570 - acc: 0.2499 - val_loss: 1.3529 - val_acc: 0.2485\n",
      "Epoch 19/96\n",
      "11995/11995 [==============================] - 6s 500us/step - loss: 1.3493 - acc: 0.2505 - val_loss: 1.3523 - val_acc: 0.2362\n",
      "Epoch 20/96\n",
      "11995/11995 [==============================] - 4s 352us/step - loss: 1.3569 - acc: 0.2496 - val_loss: 1.3503 - val_acc: 0.2472\n",
      "Epoch 21/96\n",
      "11995/11995 [==============================] - 4s 347us/step - loss: 1.3491 - acc: 0.2543 - val_loss: 1.3490 - val_acc: 0.2495\n",
      "Epoch 22/96\n",
      "11995/11995 [==============================] - 6s 488us/step - loss: 1.3514 - acc: 0.2514 - val_loss: 1.3517 - val_acc: 0.2418\n",
      "Epoch 23/96\n",
      "11995/11995 [==============================] - 4s 355us/step - loss: 1.3487 - acc: 0.2509 - val_loss: 1.3511 - val_acc: 0.2388\n",
      "Epoch 24/96\n",
      "11995/11995 [==============================] - 4s 356us/step - loss: 1.3475 - acc: 0.2557 - val_loss: 1.3461 - val_acc: 0.2438\n",
      "Epoch 25/96\n",
      "11995/11995 [==============================] - 7s 542us/step - loss: 1.3465 - acc: 0.2532 - val_loss: 1.3667 - val_acc: 0.2201\n",
      "Epoch 26/96\n",
      "11995/11995 [==============================] - 5s 417us/step - loss: 1.3483 - acc: 0.2564 - val_loss: 1.3530 - val_acc: 0.2385\n",
      "Epoch 27/96\n",
      "11995/11995 [==============================] - 5s 424us/step - loss: 1.3497 - acc: 0.2539 - val_loss: 1.3468 - val_acc: 0.2488\n",
      "Epoch 28/96\n",
      "11995/11995 [==============================] - 4s 350us/step - loss: 1.3483 - acc: 0.2526 - val_loss: 1.3437 - val_acc: 0.2422\n",
      "Epoch 29/96\n",
      "11995/11995 [==============================] - 4s 350us/step - loss: 1.3445 - acc: 0.2517 - val_loss: 1.3442 - val_acc: 0.2445\n",
      "Epoch 30/96\n",
      "11995/11995 [==============================] - 5s 452us/step - loss: 1.3433 - acc: 0.2534 - val_loss: 1.3456 - val_acc: 0.2368\n",
      "Epoch 31/96\n",
      "11995/11995 [==============================] - 4s 359us/step - loss: 1.3451 - acc: 0.2523 - val_loss: 1.3447 - val_acc: 0.2405\n",
      "Epoch 32/96\n",
      "11995/11995 [==============================] - 4s 350us/step - loss: 1.3425 - acc: 0.2508 - val_loss: 1.3464 - val_acc: 0.2365\n",
      "Epoch 33/96\n",
      "11995/11995 [==============================] - 6s 460us/step - loss: 1.3385 - acc: 0.2526 - val_loss: 1.3401 - val_acc: 0.2518\n",
      "Epoch 34/96\n",
      "11995/11995 [==============================] - 5s 399us/step - loss: 1.3509 - acc: 0.2514 - val_loss: 1.3441 - val_acc: 0.2455\n",
      "Epoch 35/96\n",
      "11995/11995 [==============================] - 4s 351us/step - loss: 1.3365 - acc: 0.2565 - val_loss: 1.3419 - val_acc: 0.2455\n",
      "Epoch 36/96\n",
      "11995/11995 [==============================] - 4s 352us/step - loss: 1.3391 - acc: 0.2540 - val_loss: 1.3418 - val_acc: 0.2458\n",
      "Epoch 37/96\n",
      "11995/11995 [==============================] - 4s 356us/step - loss: 1.3375 - acc: 0.2574 - val_loss: 1.3394 - val_acc: 0.2498\n",
      "Epoch 38/96\n",
      "11995/11995 [==============================] - 4s 352us/step - loss: 1.3373 - acc: 0.2543 - val_loss: 1.3456 - val_acc: 0.2438\n",
      "Epoch 39/96\n",
      "11995/11995 [==============================] - 5s 398us/step - loss: 1.3462 - acc: 0.2501 - val_loss: 1.3428 - val_acc: 0.2442\n",
      "Epoch 40/96\n",
      "11995/11995 [==============================] - 5s 395us/step - loss: 1.3376 - acc: 0.2570 - val_loss: 1.3388 - val_acc: 0.2458\n",
      "Epoch 41/96\n",
      "11995/11995 [==============================] - 4s 352us/step - loss: 1.3379 - acc: 0.2559 - val_loss: 1.3419 - val_acc: 0.2438\n",
      "Epoch 42/96\n",
      "11995/11995 [==============================] - 4s 351us/step - loss: 1.3383 - acc: 0.2541 - val_loss: 1.3370 - val_acc: 0.2445\n",
      "Epoch 43/96\n",
      "11995/11995 [==============================] - 4s 347us/step - loss: 1.3382 - acc: 0.2584 - val_loss: 1.3391 - val_acc: 0.2445\n",
      "Epoch 44/96\n",
      "11995/11995 [==============================] - 4s 353us/step - loss: 1.3377 - acc: 0.2514 - val_loss: 1.3449 - val_acc: 0.2368\n",
      "Epoch 45/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3340 - acc: 0.2578 - val_loss: 1.3405 - val_acc: 0.2388\n",
      "Epoch 46/96\n",
      "11995/11995 [==============================] - 4s 351us/step - loss: 1.3392 - acc: 0.2514 - val_loss: 1.3463 - val_acc: 0.2368\n",
      "Epoch 47/96\n",
      "11995/11995 [==============================] - 4s 346us/step - loss: 1.3370 - acc: 0.2572 - val_loss: 1.3369 - val_acc: 0.2472\n",
      "Epoch 48/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3351 - acc: 0.2559 - val_loss: 1.3356 - val_acc: 0.2462\n",
      "Epoch 49/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3340 - acc: 0.2535 - val_loss: 1.3379 - val_acc: 0.2455\n",
      "Epoch 50/96\n",
      "11995/11995 [==============================] - 4s 347us/step - loss: 1.3380 - acc: 0.2576 - val_loss: 1.3370 - val_acc: 0.2445\n",
      "Epoch 51/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3376 - acc: 0.2552 - val_loss: 1.3427 - val_acc: 0.2372\n",
      "Epoch 52/96\n",
      "11995/11995 [==============================] - 4s 346us/step - loss: 1.3315 - acc: 0.2505 - val_loss: 1.3420 - val_acc: 0.2412\n",
      "Epoch 53/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3350 - acc: 0.2531 - val_loss: 1.3333 - val_acc: 0.2482\n",
      "Epoch 54/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3317 - acc: 0.2518 - val_loss: 1.3388 - val_acc: 0.2415\n",
      "Epoch 55/96\n",
      "11995/11995 [==============================] - 4s 346us/step - loss: 1.3309 - acc: 0.2544 - val_loss: 1.3374 - val_acc: 0.2388\n",
      "Epoch 56/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3351 - acc: 0.2512 - val_loss: 1.3437 - val_acc: 0.2338\n",
      "Epoch 57/96\n",
      "11995/11995 [==============================] - 4s 374us/step - loss: 1.3357 - acc: 0.2569 - val_loss: 1.3426 - val_acc: 0.2405\n",
      "Epoch 58/96\n",
      "11995/11995 [==============================] - 5s 399us/step - loss: 1.3358 - acc: 0.2533 - val_loss: 1.3361 - val_acc: 0.2445\n",
      "Epoch 59/96\n",
      "11995/11995 [==============================] - 4s 369us/step - loss: 1.3325 - acc: 0.2540 - val_loss: 1.3344 - val_acc: 0.2448\n",
      "Epoch 60/96\n",
      "11995/11995 [==============================] - 4s 353us/step - loss: 1.3315 - acc: 0.2546 - val_loss: 1.3373 - val_acc: 0.2395\n",
      "Epoch 61/96\n",
      "11995/11995 [==============================] - 4s 346us/step - loss: 1.3296 - acc: 0.2566 - val_loss: 1.3412 - val_acc: 0.2405\n",
      "Epoch 62/96\n",
      "11995/11995 [==============================] - 4s 347us/step - loss: 1.3309 - acc: 0.2524 - val_loss: 1.3341 - val_acc: 0.2478\n",
      "Epoch 63/96\n",
      "11995/11995 [==============================] - 4s 350us/step - loss: 1.3307 - acc: 0.2543 - val_loss: 1.3376 - val_acc: 0.2452\n",
      "Epoch 64/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3315 - acc: 0.2581 - val_loss: 1.3452 - val_acc: 0.2345\n",
      "Epoch 65/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3242 - acc: 0.2606 - val_loss: 1.3440 - val_acc: 0.2348\n",
      "Epoch 66/96\n",
      "11995/11995 [==============================] - 4s 345us/step - loss: 1.3246 - acc: 0.2599 - val_loss: 1.3304 - val_acc: 0.2492\n",
      "Epoch 67/96\n",
      "11995/11995 [==============================] - 4s 346us/step - loss: 1.3313 - acc: 0.2526 - val_loss: 1.3311 - val_acc: 0.2528\n",
      "Epoch 68/96\n",
      "11995/11995 [==============================] - 4s 365us/step - loss: 1.3316 - acc: 0.2553 - val_loss: 1.3330 - val_acc: 0.2495\n",
      "Epoch 69/96\n",
      "11995/11995 [==============================] - 5s 391us/step - loss: 1.3240 - acc: 0.2551 - val_loss: 1.3273 - val_acc: 0.2528\n",
      "Epoch 70/96\n",
      "11995/11995 [==============================] - 4s 346us/step - loss: 1.3194 - acc: 0.2571 - val_loss: 1.3266 - val_acc: 0.2505\n",
      "Epoch 71/96\n",
      "11995/11995 [==============================] - 4s 347us/step - loss: 1.3324 - acc: 0.2607 - val_loss: 1.3423 - val_acc: 0.2302\n",
      "Epoch 72/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3238 - acc: 0.2562 - val_loss: 1.3323 - val_acc: 0.2442\n",
      "Epoch 73/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3245 - acc: 0.2599 - val_loss: 1.3296 - val_acc: 0.2462\n",
      "Epoch 74/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3251 - acc: 0.2515 - val_loss: 1.3364 - val_acc: 0.2405\n",
      "Epoch 75/96\n",
      "11995/11995 [==============================] - 4s 361us/step - loss: 1.3379 - acc: 0.2563 - val_loss: 1.3370 - val_acc: 0.2385\n",
      "Epoch 76/96\n",
      "11995/11995 [==============================] - 5s 394us/step - loss: 1.3199 - acc: 0.2606 - val_loss: 1.3343 - val_acc: 0.2445\n",
      "Epoch 77/96\n",
      "11995/11995 [==============================] - 5s 387us/step - loss: 1.3208 - acc: 0.2564 - val_loss: 1.3310 - val_acc: 0.2445\n",
      "Epoch 78/96\n",
      "11995/11995 [==============================] - 4s 350us/step - loss: 1.3224 - acc: 0.2555 - val_loss: 1.3352 - val_acc: 0.2492\n",
      "Epoch 79/96\n",
      "11995/11995 [==============================] - 4s 347us/step - loss: 1.3257 - acc: 0.2553 - val_loss: 1.3323 - val_acc: 0.2458\n",
      "Epoch 80/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3272 - acc: 0.2541 - val_loss: 1.3356 - val_acc: 0.2455\n",
      "Epoch 81/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3193 - acc: 0.2550 - val_loss: 1.3366 - val_acc: 0.2402\n",
      "Epoch 82/96\n",
      "11995/11995 [==============================] - 4s 348us/step - loss: 1.3247 - acc: 0.2585 - val_loss: 1.3340 - val_acc: 0.2402\n",
      "Epoch 83/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3313 - acc: 0.2548 - val_loss: 1.3260 - val_acc: 0.2472\n",
      "Epoch 84/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3240 - acc: 0.2584 - val_loss: 1.3275 - val_acc: 0.2455\n",
      "Epoch 85/96\n",
      "11995/11995 [==============================] - 4s 347us/step - loss: 1.3251 - acc: 0.2591 - val_loss: 1.3322 - val_acc: 0.2422\n",
      "Epoch 86/96\n",
      "11995/11995 [==============================] - 4s 349us/step - loss: 1.3266 - acc: 0.2609 - val_loss: 1.3351 - val_acc: 0.2445\n",
      "Epoch 87/96\n",
      "11995/11995 [==============================] - 4s 346us/step - loss: 1.3250 - acc: 0.2558 - val_loss: 1.3428 - val_acc: 0.2358\n",
      "Epoch 88/96\n",
      "11995/11995 [==============================] - 4s 344us/step - loss: 1.3261 - acc: 0.2550 - val_loss: 1.3297 - val_acc: 0.2468\n",
      "Epoch 89/96\n",
      "11995/11995 [==============================] - 4s 344us/step - loss: 1.3233 - acc: 0.2634 - val_loss: 1.3392 - val_acc: 0.2398\n",
      "Epoch 90/96\n",
      "11995/11995 [==============================] - 4s 340us/step - loss: 1.3242 - acc: 0.2529 - val_loss: 1.3478 - val_acc: 0.2322\n",
      "Epoch 91/96\n",
      "11995/11995 [==============================] - 4s 344us/step - loss: 1.3252 - acc: 0.2585 - val_loss: 1.3350 - val_acc: 0.2418\n",
      "Epoch 92/96\n",
      "11995/11995 [==============================] - 4s 340us/step - loss: 1.3260 - acc: 0.2519 - val_loss: 1.3289 - val_acc: 0.2478\n",
      "Epoch 93/96\n",
      "11995/11995 [==============================] - 4s 353us/step - loss: 1.3277 - acc: 0.2517 - val_loss: 1.3395 - val_acc: 0.2362\n",
      "Epoch 94/96\n",
      "11995/11995 [==============================] - 5s 406us/step - loss: 1.3214 - acc: 0.2588 - val_loss: 1.3342 - val_acc: 0.2392\n",
      "Epoch 95/96\n",
      "11995/11995 [==============================] - 5s 401us/step - loss: 1.3274 - acc: 0.2596 - val_loss: 1.3319 - val_acc: 0.2425\n",
      "Epoch 96/96\n",
      "11995/11995 [==============================] - 4s 356us/step - loss: 1.3199 - acc: 0.2590 - val_loss: 1.3303 - val_acc: 0.2452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Fit to the data\\nfor _ in range(epochs):\\n    #Ys = numpy.array([inv_label(y) for y in Y_train])\\n    history = attr_clf.model.fit(X_train, Y_train)\\n    \\n    Ys = attr_clf.model.predict(X_valid)\\n    Ys = [label(y) for y in Ys]\\n    acc = sum(Ys[i] == Y_valid[i] for i in range(len(Ys))) / len(Y_valid)\\n    print('val_acc:', acc)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "# Attribute model data\n",
    "X_attr, Y_attr = convert_for_single_axis(X, Y, ax=0)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle(X, Y)\n",
    "\n",
    "# Validation split\n",
    "(X_train, Y_train), (X_valid, Y_valid) = split(X_attr, Y_attr)\n",
    "\n",
    "print('Training points:', len(Y_train))\n",
    "print('Validation points:', len(Y_valid))\n",
    "print('Total points:', len(Y))\n",
    "\n",
    "attr_clf = RegModel((X_train, Y_train), (X_valid, Y_valid))\n",
    "\n",
    "# Build the model\n",
    "attr_clf.compile(optimizer=Adam(lr=2e-4))\n",
    "\n",
    "import random\n",
    "ivs = [0, 1, 7, 31, 90, 180]\n",
    "\n",
    "def label(y):\n",
    "    if y < 1:\n",
    "        return 0\n",
    "    elif y < 7:\n",
    "        return 1\n",
    "    elif y < 31:\n",
    "        return 2\n",
    "    elif y < 90:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def inv_label(x):\n",
    "    return numpy.random.uniform(ivs[x], ivs[x+1])\n",
    "\n",
    "epochs=96\n",
    "\n",
    "history = attr_clf.train(epochs=epochs)\n",
    "\"\"\"\n",
    "# Fit to the data\n",
    "for _ in range(epochs):\n",
    "    #Ys = numpy.array([inv_label(y) for y in Y_train])\n",
    "    history = attr_clf.model.fit(X_train, Y_train)\n",
    "    \n",
    "    Ys = attr_clf.model.predict(X_valid)\n",
    "    Ys = [label(y) for y in Ys]\n",
    "    acc = sum(Ys[i] == Y_valid[i] for i in range(len(Ys))) / len(Y_valid)\n",
    "    print('val_acc:', acc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "aOs9TyY8Y88p",
    "outputId": "8f112388-ae2c-4fa9-822d-d796c1f95ff5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA6R6FUz2pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "mi3jBds77UpB",
    "outputId": "de3c576e-14e8-4141-c0a9-6711be38cf40"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-db006b3709db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mattr_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RegModel' object has no attribute 'val_acc'"
     ]
    }
   ],
   "source": [
    "# Garbage collection prevents memory limit from being exceeded\n",
    "del X_attr\n",
    "del Y_attr\n",
    "import gc\n",
    "gc.collect()\n",
    "attr_clf.val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqPthCWDQ0t1"
   },
   "outputs": [],
   "source": [
    "# Get the test data\n",
    "X_test, ids = load_train_data(is_train=False)\n",
    "X_test = X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "0fh7_wigSSv1",
    "outputId": "fb88ec21-9637-4d2a-e960-8108ac8b7470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3948, 23)\n",
      "(None, 23)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(attr_clf.model.input_shape)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_test = attr_clf.model.predict(X_test).flatten()\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    x = Y_test[i]\n",
    "    if x < 1:\n",
    "        y = 0\n",
    "    elif x < 7:\n",
    "        y = 1\n",
    "    elif x < 31:\n",
    "        y = 2\n",
    "    elif x < 90:\n",
    "        y = 3\n",
    "    else:\n",
    "        y = 4\n",
    "        \n",
    "    Y_test[i] = y\n",
    "\n",
    "Y_test.shape\n",
    "print(Y_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FeQcejAuVaC"
   },
   "source": [
    "#### CNN Model\n",
    "\n",
    "We will aim to learn from the images on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "B_ozmsXq9MG1",
    "outputId": "f3a0de32-0ef7-4e96-ca15-40311bc65065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 14993 datapoints\n",
      "Training points: 46922\n",
      "Validation points: 11730\n",
      "Total points: 14993\n",
      "(46922, 64, 64, 3) (11730, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create inputs for convolutional model\n",
    "X_conv, Y_conv = convert_for_all(X, Y)\n",
    "X_train = X_conv[1]\n",
    "\n",
    "# Image generator for training\n",
    "def make_generator(X):\n",
    "    gen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            zoom_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "    )\n",
    "    gen.fit(X)\n",
    "    return gen\n",
    "\n",
    "Y_conv = to_categorical(Y_conv)\n",
    "\n",
    "# Validation split\n",
    "(X_train, Y_train), (X_valid, Y_valid) = split(X_train, Y_conv)\n",
    "print('Training points:', len(Y_train))\n",
    "print('Validation points:', len(Y_valid))\n",
    "print('Total points:', len(Y))\n",
    "print(X_train.shape, X_valid.shape)\n",
    "\n",
    "train_gen = make_generator(X_train).flow(X_train, Y_train, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2845
    },
    "colab_type": "code",
    "id": "_f5oILJKvt1_",
    "outputId": "7253b59f-e569-46dc-845e-54bbdd61abb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 64, 64, 64)        205440    \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 64, 64, 64)        205440    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        4160      \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 32, 32, 64)        205440    \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 32, 32, 64)        205440    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        4160      \n",
      "_________________________________________________________________\n",
      "model_5 (Model)              (None, 16, 16, 64)        205440    \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, 16, 16, 64)        205440    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 64)          4160      \n",
      "_________________________________________________________________\n",
      "model_7 (Model)              (None, 8, 8, 64)          205440    \n",
      "_________________________________________________________________\n",
      "model_8 (Model)              (None, 8, 8, 64)          205440    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 4, 4, 64)          4160      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 1,801,600\n",
      "Trainable params: 1,799,168\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "single_image_encoder (Sequen (None, 128)               1801600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,802,245\n",
      "Trainable params: 1,799,813\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "Compiling single_image\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/96\n",
      "1466/1466 [==============================] - 125s 85ms/step - loss: 1.5622 - acc: 0.2625 - val_loss: 1.4743 - val_acc: 0.2511\n",
      "Epoch 2/96\n",
      "1466/1466 [==============================] - 109s 75ms/step - loss: 1.4911 - acc: 0.2633 - val_loss: 1.4637 - val_acc: 0.2594\n",
      "Epoch 3/96\n",
      "1466/1466 [==============================] - 110s 75ms/step - loss: 1.4813 - acc: 0.2666 - val_loss: 1.4694 - val_acc: 0.2555\n",
      "Epoch 4/96\n",
      "1466/1466 [==============================] - 109s 75ms/step - loss: 1.4732 - acc: 0.2708 - val_loss: 1.4748 - val_acc: 0.2429\n",
      "Epoch 5/96\n",
      "1466/1466 [==============================] - 109s 74ms/step - loss: 1.4704 - acc: 0.2711 - val_loss: 1.4601 - val_acc: 0.2650\n",
      "Epoch 6/96\n",
      "1466/1466 [==============================] - 103s 71ms/step - loss: 1.4687 - acc: 0.2752 - val_loss: 1.4569 - val_acc: 0.2733\n",
      "Epoch 7/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4650 - acc: 0.2770 - val_loss: 1.5156 - val_acc: 0.2685\n",
      "Epoch 8/96\n",
      "1466/1466 [==============================] - 102s 70ms/step - loss: 1.4677 - acc: 0.2722 - val_loss: 1.4568 - val_acc: 0.2448\n",
      "Epoch 9/96\n",
      "1466/1466 [==============================] - 102s 70ms/step - loss: 1.4632 - acc: 0.2703 - val_loss: 1.9390 - val_acc: 0.2430\n",
      "Epoch 10/96\n",
      "1466/1466 [==============================] - 102s 70ms/step - loss: 1.4624 - acc: 0.2816 - val_loss: 1.4638 - val_acc: 0.2579\n",
      "Epoch 11/96\n",
      "1466/1466 [==============================] - 102s 69ms/step - loss: 1.4673 - acc: 0.2739 - val_loss: 1.4562 - val_acc: 0.2727\n",
      "Epoch 12/96\n",
      "1466/1466 [==============================] - 102s 70ms/step - loss: 1.4631 - acc: 0.2775 - val_loss: 1.4679 - val_acc: 0.2713\n",
      "Epoch 13/96\n",
      "1466/1466 [==============================] - 102s 70ms/step - loss: 1.4586 - acc: 0.2779 - val_loss: 1.4621 - val_acc: 0.2660\n",
      "Epoch 14/96\n",
      "1466/1466 [==============================] - 103s 71ms/step - loss: 1.4626 - acc: 0.2700 - val_loss: 1.4634 - val_acc: 0.2754\n",
      "Epoch 15/96\n",
      "1466/1466 [==============================] - 106s 72ms/step - loss: 1.4664 - acc: 0.2718 - val_loss: 1.4647 - val_acc: 0.2761\n",
      "Epoch 16/96\n",
      "1466/1466 [==============================] - 105s 71ms/step - loss: 1.4601 - acc: 0.2804 - val_loss: 1.4599 - val_acc: 0.2821\n",
      "Epoch 17/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4546 - acc: 0.2765 - val_loss: 1.5133 - val_acc: 0.2746\n",
      "Epoch 18/96\n",
      "1466/1466 [==============================] - 103s 71ms/step - loss: 1.4624 - acc: 0.2841 - val_loss: 1.4582 - val_acc: 0.2725\n",
      "Epoch 19/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4633 - acc: 0.2759 - val_loss: 1.4609 - val_acc: 0.2585\n",
      "Epoch 20/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4576 - acc: 0.2849 - val_loss: 1.4552 - val_acc: 0.2725\n",
      "Epoch 21/96\n",
      "1466/1466 [==============================] - 104s 71ms/step - loss: 1.4603 - acc: 0.2691 - val_loss: 1.4604 - val_acc: 0.2561\n",
      "Epoch 22/96\n",
      "1466/1466 [==============================] - 103s 71ms/step - loss: 1.4591 - acc: 0.2845 - val_loss: 1.4603 - val_acc: 0.2754\n",
      "Epoch 23/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4606 - acc: 0.2784 - val_loss: 1.4619 - val_acc: 0.2552\n",
      "Epoch 24/96\n",
      "1466/1466 [==============================] - 104s 71ms/step - loss: 1.4586 - acc: 0.2805 - val_loss: 1.4847 - val_acc: 0.2742\n",
      "Epoch 25/96\n",
      "1466/1466 [==============================] - 103s 71ms/step - loss: 1.4589 - acc: 0.2821 - val_loss: 2.0411 - val_acc: 0.2061\n",
      "Epoch 26/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4542 - acc: 0.2891 - val_loss: 1.4724 - val_acc: 0.2807\n",
      "Epoch 27/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4544 - acc: 0.2885 - val_loss: 1.4855 - val_acc: 0.2727\n",
      "Epoch 28/96\n",
      "1466/1466 [==============================] - 103s 71ms/step - loss: 1.4576 - acc: 0.2803 - val_loss: 1.4612 - val_acc: 0.2672\n",
      "Epoch 29/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4624 - acc: 0.2795 - val_loss: 1.4662 - val_acc: 0.2844\n",
      "Epoch 30/96\n",
      "1466/1466 [==============================] - 104s 71ms/step - loss: 1.4594 - acc: 0.2858 - val_loss: 1.4590 - val_acc: 0.2761\n",
      "Epoch 31/96\n",
      "1466/1466 [==============================] - 103s 71ms/step - loss: 1.4588 - acc: 0.2803 - val_loss: 1.4770 - val_acc: 0.2847\n",
      "Epoch 32/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4552 - acc: 0.2902 - val_loss: 1.4629 - val_acc: 0.2653\n",
      "Epoch 33/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4596 - acc: 0.2864 - val_loss: 1.4632 - val_acc: 0.2543\n",
      "Epoch 34/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4513 - acc: 0.2862 - val_loss: 1.4744 - val_acc: 0.2766\n",
      "Epoch 35/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4583 - acc: 0.2842 - val_loss: 1.4527 - val_acc: 0.2673\n",
      "Epoch 36/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4577 - acc: 0.2771 - val_loss: 1.4619 - val_acc: 0.2758\n",
      "Epoch 37/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4525 - acc: 0.2866 - val_loss: 1.4576 - val_acc: 0.2667\n",
      "Epoch 38/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4619 - acc: 0.2822 - val_loss: 1.4642 - val_acc: 0.2717\n",
      "Epoch 39/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4535 - acc: 0.2902 - val_loss: 1.4632 - val_acc: 0.2835\n",
      "Epoch 40/96\n",
      "1466/1466 [==============================] - 103s 70ms/step - loss: 1.4533 - acc: 0.2867 - val_loss: 1.4610 - val_acc: 0.2823\n",
      "Epoch 41/96\n",
      " 396/1466 [=======>......................] - ETA: 1:02 - loss: 1.4566 - acc: 0.2909Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "\n",
    "# Build a model\n",
    "conv_clf = SingleImageModel((X_train, Y_train), (X_valid, Y_valid))\n",
    "#conv_clf = VggModel((X_train, Y_train), (X_valid, Y_valid))\n",
    "\n",
    "# Train the model\n",
    "conv_clf.compile(optimizer=Adam(lr=2e-4))\n",
    "history = conv_clf.model.fit_generator(train_gen, steps_per_epoch = len(X_train) // 32, epochs=96, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cSoA2ua474nQ",
    "outputId": "ef6c7ebb-152b-483a-9eee-5da83cecbf14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28380222100913777"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_clf.val_acc = history.history['val_acc'][-1]\n",
    "conv_clf.val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "Ev41Ml5nDs9_",
    "outputId": "4819bc88-69fa-49f9-9e8f-dc446df65364"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nguVVJNYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "odpnHYS_-X2n",
    "outputId": "215616bb-3337-4f27-ff49-df7bcc641d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28380221653878945\n",
      "Kappa: 0.03451317223370476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "X_valid, Y_valid = conv_clf.test_data\n",
    "\n",
    "Y_pred = conv_clf.predict(X_valid)\n",
    "\n",
    "# Convert to numeric labels\n",
    "Y_valid = np.argmax(Y_valid, -1)\n",
    "Y_pred = np.argmax(Y_pred, -1)\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_valid, Y_pred))\n",
    "print('Kappa:', cohen_kappa_score(Y_valid, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wGArB-AK_VRU",
    "outputId": "9d21b653-7e3c-4a5e-e69e-e3bd1f9c678a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_conv\n",
    "del Y_conv\n",
    "del X_train\n",
    "del Y_train\n",
    "del X_valid\n",
    "del Y_valid\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38YiVafJ-hFo"
   },
   "source": [
    "#### Multi-Image Model\n",
    "\n",
    "The motivation is to be able to use an arbitrary number of images to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTWSwEvO-th_"
   },
   "outputs": [],
   "source": [
    "# Attribute model data\n",
    "X_poly, Y_poly = convert_for_poly(X, Y)\n",
    "X_poly = X_poly[1]\n",
    "print(X_poly.shape, Y_poly.shape)\n",
    "\n",
    "# Image-free model\n",
    "poly_clf = PolyImageModel\n",
    "\n",
    "# Train the model\n",
    "poly_clf = train_model(poly_clf, X_poly, Y_poly, epochs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUWb0gBCkJyg"
   },
   "source": [
    "#### Union Model\n",
    "\n",
    "A model using both attribute and image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kc_Qv1ongWk8"
   },
   "outputs": [],
   "source": [
    "# Create inputs for convolutional model\n",
    "#X_conv, Y_conv = convert_for_all(X, Y)\n",
    "#print('Built data')\n",
    "#print([x.shape for x in X_conv])\n",
    "#print(Y_conv.shape)\n",
    "\n",
    "def make_union(tr, tst):\n",
    "    attr = OheModel(tr, tst)\n",
    "    conv = SingleImageModel(tr, tst)\n",
    "    \n",
    "    return UnionModel([attr, conv], tr, tst, freeze=False)\n",
    "\n",
    "# Build a model\n",
    "#union_clf = lambda tr, tst: UnionModel([attr_clf, conv_clf], tr, tst, freeze=True)\n",
    "union_clf = make_union\n",
    "\n",
    "# Train the model\n",
    "union_clf = train_model(union_clf, X_conv, Y_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7P2rPR5UbhO"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Cat105rUYtP"
   },
   "outputs": [],
   "source": [
    "# Get the test data\n",
    "X, ids = load_train_data(is_train=False)\n",
    "X = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWmhXvpJVGrW"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "Y = attr_clf.model.predict(X)\n",
    "Y = np.argmax(Y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o18H5BcoV4lG"
   },
   "outputs": [],
   "source": [
    "# Save the results to a file\n",
    "df = pd.DataFrame({\n",
    "    'PetID': ids,\n",
    "    'AdoptionSpeed':Y\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "OurModels.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
