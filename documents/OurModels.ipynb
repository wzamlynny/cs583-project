{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th6gTo_1vt1n"
   },
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na3nfkze_NmF"
   },
   "source": [
    "If you are not using Google Colab, you need not run this. The purpose of this element is to navigate to the files on Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "8XeYsxujwhsE",
    "outputId": "f1985e3f-b3c1-4c7e-aa15-da1f82a4a1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/data_583\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount my Google Drrive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Go to the directory with the 583 data\n",
    "os.chdir('/content/drive/My Drive/data_583')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDreCUSLvt1o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "numeric_cols = [\n",
    "    'Age',\n",
    "    'Quantity', 'Fee', 'State',\n",
    "    'VideoAmt', 'PhotoAmt', 'Type'\n",
    "]\n",
    "\n",
    "one_hot_cols = {\n",
    "    #'Type': 2, \n",
    "    'Breed1': 307, 'Breed2': 307,\n",
    "    'Gender': 3, 'Color1': 7, 'Color2': 7,\n",
    "    'Color3': 7,\n",
    "    'MaturitySize': 5,\n",
    "    'FurLength': 4, 'Vaccinated': 3,\n",
    "    'Dewormed': 3, 'Sterilized': 3,\n",
    "    'Health': 4, 'State': 15\n",
    "}\n",
    "\n",
    "def one_hot_encode(df, col, num_class=None, labels=None, inplace=False):\n",
    "    ''' Takes in dataframe df and replaces col with num_class columns\n",
    "        For example, use as follows\n",
    "        for col, num_class in data.one_hot_cols.items():\n",
    "            one_hot_encode(train_df, col, num_class)\n",
    "    '''\n",
    "    # get the true values from data\n",
    "    column_values = np.sort(df[col].dropna().unique())\n",
    "    if num_class == None:\n",
    "        num_class = len(column_values)\n",
    "    if num_class == 2:\n",
    "        # These can just be boolean\n",
    "        if inplace:\n",
    "            df[col] = (df[col] == column_values[0]).astype(int)\n",
    "        else:\n",
    "            return (df[col] == column_values[0]).astype(int)\n",
    "    else:        \n",
    "        if labels is not None:\n",
    "            res = np.zeros((len(df), num_class))\n",
    "            for i, label in enumerate(labels):\n",
    "                if inplace:\n",
    "                    df[col+'_'+str(label)] = (df[col] == label).astype(int)\n",
    "                else:\n",
    "                    one_hot = np.zeros(num_class)\n",
    "                    one_hot[i] = 1\n",
    "                    res[df[col] == label] = one_hot\n",
    "        else:\n",
    "            res = np.zeros((len(df), num_class))\n",
    "            for i in range(num_class):\n",
    "                if (i >= len(column_values)):\n",
    "                    break # Index out of bounds\n",
    "                cur_value = column_values[i]\n",
    "\n",
    "                if inplace:\n",
    "                    df[col+'_'+str(cur_value)] = (df[col] == cur_value).astype(int)\n",
    "                else:\n",
    "                    one_hot = np.zeros(num_class)\n",
    "                    one_hot[i] = 1\n",
    "                    res[df[col] == cur_value] = one_hot\n",
    "    \n",
    "        if inplace:\n",
    "            # delete original column\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "def load_data(fname):\n",
    "    return pd.read_csv(fname)\n",
    "\n",
    "def load_pet_files(regdir):\n",
    "    \"\"\" Extracts all of the files associated with each pet listed\n",
    "    by the 'PetID' tag.\n",
    "\n",
    "    regdir - The directory containing the files\n",
    "\n",
    "    returns a dictionary containing keypairs (k, v) such that v\n",
    "    matches the regex (k\\-.*) where k is the key (a valid PetID).\n",
    "    \"\"\"\n",
    "    fname = os.path.join(regdir, 'picked_pictures.npy')\n",
    "    \n",
    "    print(f\"Images will be loaded from {fname}\")\n",
    "    return np.load(fname)\n",
    "\n",
    "def load_pet_pics(regdir):\n",
    "    \"\"\" Extracts all of the files associated with each pet listed\n",
    "    by the 'PetID' tag.\n",
    "\n",
    "    regdir - The directory containing the files\n",
    "\n",
    "    returns a dictionary containing keypairs (k, v) such that v\n",
    "    matches the regex (k\\-.*) where k is the key (a valid PetID).\n",
    "    \"\"\"\n",
    "    if os.path.isfile(os.path.join(regdir + 'picked_pictures.npy')):\n",
    "        print(\"Images loaded from existing file\")\n",
    "        return np.load(os.path.join(regdir + 'picked_pictures.npy'))\n",
    "    pfiles = {}\n",
    "\n",
    "    # Extract the pet names\n",
    "    for f in tqdm(os.listdir(regdir), desc='Loading Pet Files'):\n",
    "        # Extract the name\n",
    "        n = f[:f.index('-')]\n",
    "        url = os.path.join(regdir, f)\n",
    "        img = load_image(url)\n",
    "        if n in pfiles:\n",
    "            # Add to the entry\n",
    "            pfiles[n].append(img)\n",
    "\n",
    "        else:\n",
    "            # Add a new entry\n",
    "            pfiles[n] = [img]\n",
    "\n",
    "    np.save(os.path.join(regdir + 'picked_pictures.npy'), pfiles)\n",
    "    return pfiles\n",
    "\n",
    "def load_train_data(is_train = True):\n",
    "    # Get the annotations for each pet\n",
    "    dta = load_data('data/train/train.csv' if is_train else 'data/test/test.csv')\n",
    "     \n",
    "    # Get the pet pictures\n",
    "    petpics = load_pet_files('data/') if is_train else load_pet_files('data/test_images')\n",
    "\n",
    "    # Get the state ids\n",
    "    states = load_data('data/state_labels.csv')\n",
    "    states = states['StateID'].tolist()\n",
    "\n",
    "    # Load parsed sentiment\n",
    "    sentiment = load_data('data/{}_sentiment_parsed.csv'.format('train' if is_train else 'test'))\n",
    "\n",
    "    X_num = []\n",
    "    X_pic = []\n",
    "\n",
    "    Y = []\n",
    "    \n",
    "    # Build a single object to store the X values\n",
    "    X = [X_num, X_pic]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for k in one_hot_cols:\n",
    "        one_hot_encode(dta, k, inplace=True)\n",
    "        print('One hot encoded', k)\n",
    "        \"\"\"\n",
    "    \n",
    "    for i, row in dta.iterrows():\n",
    "        # Save the numeric values\n",
    "        vals = row[numeric_cols]\n",
    "        \n",
    "        state = [x == row['State'] for x in states]\n",
    "        #assert(sum(state) == 1)\n",
    "        \n",
    "        # Add all of the valid one-hot encodings\n",
    "        #state = [row[k] for k in dta if any(q in k for q in one_hot_cols)]\n",
    "            \n",
    "        x = list(vals) + state\n",
    "        \n",
    "            \n",
    "        # Join sentiment on PetID\n",
    "        s = sentiment[sentiment['PetID'] == row['PetID']]\n",
    "        \n",
    "        for col in s:\n",
    "            if col not in row:\n",
    "                row[col] = s.iloc[0][col]\n",
    "                x.append(row[col])\n",
    "        \n",
    "        # Save the pictures\n",
    "        if row['PetID'] in petpics:\n",
    "            X_pic.append(petpics[row['PetID']])\n",
    "        else:\n",
    "            X_pic.append([])\n",
    "            \n",
    "        # Save the data pair\n",
    "        X_num.append(np.array(x))\n",
    "        \n",
    "        if is_train:\n",
    "            Y.append(row['AdoptionSpeed'])\n",
    "        else:\n",
    "            Y.append(row['PetID'])\n",
    "\n",
    "    # Laziness\n",
    "    if len(X) == 1:\n",
    "        X = np.array(X[0])\n",
    "    else:\n",
    "        X = list(map(np.array, X))\n",
    "\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    return (X, Y)\n",
    "\n",
    "def load_image(img_file, size=64):\n",
    "    # print('img file:', img_file)\n",
    "    img = Image.open(img_file)\n",
    "    img = img.resize((size, size), Image.ANTIALIAS)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b6sUBRbzvt1r",
    "outputId": "92ac5f2d-098d-4191-9c5e-6d14b48703ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be loaded from data/picked_pictures.npy\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Get the data\n",
    "X, Y = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "EWNsY2aes3i5",
    "outputId": "bdb2528e-f30d-44e0-b710-928ff166cfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14993, 25), (14993, 0)]\n",
      "(14993,)\n",
      "[3.0000e+00 1.0000e+00 1.0000e+02 4.1326e+04 0.0000e+00 1.0000e+00\n",
      " 2.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 2.4000e+00 3.0000e-01\n",
      " 6.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in X])\n",
    "print(Y.shape)\n",
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP5N-nfKvt1v"
   },
   "outputs": [],
   "source": [
    "def shuffle(X, Y):\n",
    "    idxs = list(range(len(Y)))\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        for i in range(len(X)):\n",
    "            X[i] = X[i][idxs]\n",
    "    else:\n",
    "        X = X[idxs]\n",
    "\n",
    "    Y = Y[idxs]\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def split(X, Y, s=0.2):\n",
    "    s = int(s * len(Y))\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        X_train = [x[:-s] for x in X]\n",
    "        X_test = [x[-s:] for x in X]\n",
    "    else:\n",
    "        X_train = X[:-s]\n",
    "        X_test = X[-s:]\n",
    "\n",
    "    Y_train = Y[:-s]\n",
    "    Y_test = Y[-s:]\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "\n",
    "def convert_for_all(X, Y):\n",
    "    # For single image training, make a datapoint for each image or the default zero image\n",
    "    Xs = [[], []]\n",
    "    Ys = []\n",
    "    for i in range(len(X[1])):\n",
    "        Xs[0].append(X[0][i])\n",
    "        if len(X[1][i]) == 0:\n",
    "            Xs[1].append(np.zeros((64, 64, 3)))\n",
    "            Ys.append(Y[i])\n",
    "        else:\n",
    "            # Make a datapoint for all images. We assume equal relevance of images\n",
    "            for img in X[1][i]:\n",
    "                Xs[0].append(X[0][i])\n",
    "                Xs[1].append(img)\n",
    "                Ys.append(Y[i])\n",
    "\n",
    "    X = list(map(np.array, Xs))\n",
    "    Y = np.array(Ys)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def convert_for_single_axis(X, Y, ax=0):\n",
    "    return X[ax], Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkUUG-buDZ5z"
   },
   "outputs": [],
   "source": [
    "X, Y = shuffle(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsCyyd2Fvt1x"
   },
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKtOpAxGvt1y"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "class KaggleModel:\n",
    "    def __init__(self, model, train, test):\n",
    "        model.summary()\n",
    "        self.model = model\n",
    "        self.train_data = train\n",
    "        self.test_data = test\n",
    "\n",
    "    def compile(self):\n",
    "        \"\"\" Compiles the model. Should be defined by the user.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def train(self, epochs=1):\n",
    "        \"\"\" Default training behavior. Simply does a Model.fit(X, Y).\n",
    "        \"\"\"\n",
    "        # Get the training data\n",
    "        X_train, Y_train = self.train_data\n",
    "\n",
    "        checkpoint = ModelCheckpoint('model.h5')\n",
    "        \n",
    "        # Fit to the data\n",
    "        self.model.fit(X_train, Y_train, epochs=epochs, validation_data=self.test_data, callbacks=[checkpoint])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "def ResidualBlock(mdl):\n",
    "    x = Input(shape=mdl.input_shape[1:])\n",
    "\n",
    "    y = mdl(x)\n",
    "    y = Add()([x, y])\n",
    "\n",
    "    return Model(x, y)\n",
    "\n",
    "class ImageFreeModel(KaggleModel):\n",
    "    def __init__(self, train, test):\n",
    "        kernel = Sequential(name='image_free_encoder')\n",
    "        \n",
    "        kernel.add(BatchNormalization(input_shape=(25,)))\n",
    "        \n",
    "        kernel.add(Dense(128))\n",
    "        kernel.add(Activation('relu'))\n",
    "        \n",
    "        # Use a single dense residual block\n",
    "        \"\"\"\n",
    "        blk = Sequential()\n",
    "        \n",
    "        blk.add(Dropout(0.5, input_shape=kernel.output_shape[1:]))\n",
    "        blk.add(Dense(128))\n",
    "        blk.add(Activation('relu'))\n",
    "\n",
    "        blk.add(Dense(128))\n",
    "        blk.add(Activation('relu'))\n",
    "\n",
    "        kernel.add(ResidualBlock(blk))\n",
    "        \"\"\"\n",
    "\n",
    "        model = Sequential(name='image_free')\n",
    "        model.add(kernel)\n",
    "        \n",
    "        model.add(Dense(64, activation='relu'))\n",
    "\n",
    "        # Labels are one of [0, 1, 2, 3, 4]\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        # Build using the built model\n",
    "        super().__init__(model, train, test)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class SingleImageModel(KaggleModel):\n",
    "    def __init__(self, train, test):\n",
    "        # The model takes in attributes and an image.\n",
    "        kernel = Sequential(name='single_image_encoder')\n",
    "        \n",
    "        # Architecture for the images\n",
    "        kernel.add(Conv2D(64, kernel_size=(7,7), strides=(1,1), padding='same', input_shape=(64, 64, 3)))\n",
    "        kernel.add(BatchNormalization())\n",
    "\n",
    "        while kernel.output_shape[1] > 4:\n",
    "            for _ in range(2):\n",
    "                # Old output is kept as residue\n",
    "                x = z = Input(shape=(kernel.output_shape[1:]))\n",
    "\n",
    "                z = Activation('relu')(z)\n",
    "                z = Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same')(z)\n",
    "                z = BatchNormalization()(z)\n",
    "\n",
    "                z = Activation('relu')(z)\n",
    "                z = Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same')(z)\n",
    "                z = BatchNormalization()(z)\n",
    "                \n",
    "                # The sum of the residue and the new computation\n",
    "                y = Add()([x, z])\n",
    "                \n",
    "                # Add the residual block\n",
    "                blk = Model(x, y)\n",
    "                kernel.add(blk)\n",
    "            \n",
    "            # Reduce dimension\n",
    "            kernel.add(MaxPooling2D((2,2)))\n",
    "        \n",
    "        kernel.add(Flatten())\n",
    "\n",
    "        kernel.add(Dense(128, activation='relu'))\n",
    "\n",
    "        model = Sequential(name='single_image')\n",
    "\n",
    "        model.add(kernel)\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        super().__init__(model, train, test)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class UnionModel(KaggleModel):\n",
    "    def __init__(self, models, train, test, freeze=True):\n",
    "        \n",
    "        xs = []\n",
    "        ys = []\n",
    "        for model in models:\n",
    "            model = model.model\n",
    "            x = Input(shape=model.input_shape[1:], name='{}_in'.format(model.name))\n",
    "            # Get the first layer of the model. This is the encoder\n",
    "            layer = model.get_layer(index=0)\n",
    "            \n",
    "            # It must not be trainable\n",
    "            if freeze: layer.trainable = False\n",
    "            # The output only utilizes the encoder component\n",
    "            y = layer(x)\n",
    "            \n",
    "            # Output should be flat\n",
    "            if len(y.shape) > 2:\n",
    "                y = Flatten()(y)\n",
    "                \n",
    "            # Save values\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "        y = Concatenate()(ys)\n",
    "\n",
    "        y = Dense(128)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        y = Dense(5, activation='softmax')(y)\n",
    "        \n",
    "        model = Model(xs, y)\n",
    "\n",
    "        super().__init__(model, train, test)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcePWPI9vt11"
   },
   "source": [
    "### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TGnFj8Wvt12"
   },
   "outputs": [],
   "source": [
    "def train_model(mdl, X, Y, epochs=32):\n",
    "    # Shuffle the data\n",
    "    shuffle(X, Y)\n",
    "\n",
    "    # One hot encode the output\n",
    "    Y = to_categorical(Y)\n",
    "\n",
    "    # Validation split\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = split(X, Y)\n",
    "\n",
    "    print('Training points:', len(Y_train))\n",
    "    print('Validation points:', len(Y_valid))\n",
    "    print('Total points:', len(Y))\n",
    "\n",
    "    clf = mdl((X_train, Y_train), (X_valid, Y_valid))\n",
    "\n",
    "    # Build the model\n",
    "    clf.compile()\n",
    "\n",
    "    # Fit to the data\n",
    "    clf.train(epochs=epochs)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9L8-hyo8vt14"
   },
   "source": [
    "### Model Training\n",
    "\n",
    "Models are trained one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1516
    },
    "colab_type": "code",
    "id": "AAlJDEqfvt18",
    "outputId": "dbd0e901-03be-4138-8e8c-65c60de56aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training points: 11995\n",
      "Validation points: 2998\n",
      "Total points: 14993\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_free_encoder (Sequenti (None, 128)               3428      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 12,009\n",
      "Trainable params: 11,959\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11995 samples, validate on 2998 samples\n",
      "Epoch 1/32\n",
      "11995/11995 [==============================] - 4s 367us/step - loss: 1.4443 - acc: 0.3294 - val_loss: 1.4259 - val_acc: 0.3402\n",
      "Epoch 2/32\n",
      "11995/11995 [==============================] - 2s 145us/step - loss: 1.4187 - acc: 0.3546 - val_loss: 1.4261 - val_acc: 0.3462\n",
      "Epoch 3/32\n",
      "11995/11995 [==============================] - 2s 145us/step - loss: 1.4070 - acc: 0.3623 - val_loss: 1.4176 - val_acc: 0.3569\n",
      "Epoch 4/32\n",
      "11995/11995 [==============================] - 2s 143us/step - loss: 1.4025 - acc: 0.3638 - val_loss: 1.4205 - val_acc: 0.3536\n",
      "Epoch 5/32\n",
      "11995/11995 [==============================] - 2s 132us/step - loss: 1.3991 - acc: 0.3652 - val_loss: 1.4107 - val_acc: 0.3519\n",
      "Epoch 6/32\n",
      "11995/11995 [==============================] - 2s 137us/step - loss: 1.3926 - acc: 0.3718 - val_loss: 1.4103 - val_acc: 0.3496\n",
      "Epoch 7/32\n",
      "11995/11995 [==============================] - 2s 134us/step - loss: 1.3928 - acc: 0.3731 - val_loss: 1.4090 - val_acc: 0.3619\n",
      "Epoch 8/32\n",
      "11995/11995 [==============================] - 2s 135us/step - loss: 1.3870 - acc: 0.3716 - val_loss: 1.4032 - val_acc: 0.3646\n",
      "Epoch 9/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3876 - acc: 0.3762 - val_loss: 1.4085 - val_acc: 0.3646\n",
      "Epoch 10/32\n",
      "11995/11995 [==============================] - 2s 137us/step - loss: 1.3837 - acc: 0.3754 - val_loss: 1.4052 - val_acc: 0.3546\n",
      "Epoch 11/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3832 - acc: 0.3763 - val_loss: 1.4099 - val_acc: 0.3616\n",
      "Epoch 12/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3813 - acc: 0.3782 - val_loss: 1.4039 - val_acc: 0.3619\n",
      "Epoch 13/32\n",
      "11995/11995 [==============================] - 2s 134us/step - loss: 1.3778 - acc: 0.3783 - val_loss: 1.4080 - val_acc: 0.3602\n",
      "Epoch 14/32\n",
      "11995/11995 [==============================] - 2s 134us/step - loss: 1.3773 - acc: 0.3804 - val_loss: 1.4145 - val_acc: 0.3592\n",
      "Epoch 15/32\n",
      "11995/11995 [==============================] - 2s 136us/step - loss: 1.3746 - acc: 0.3857 - val_loss: 1.4108 - val_acc: 0.3549\n",
      "Epoch 16/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3746 - acc: 0.3836 - val_loss: 1.4169 - val_acc: 0.3626\n",
      "Epoch 17/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3707 - acc: 0.3817 - val_loss: 1.4082 - val_acc: 0.3569\n",
      "Epoch 18/32\n",
      "11995/11995 [==============================] - 2s 134us/step - loss: 1.3700 - acc: 0.3881 - val_loss: 1.4264 - val_acc: 0.3586\n",
      "Epoch 19/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3660 - acc: 0.3888 - val_loss: 1.4133 - val_acc: 0.3639\n",
      "Epoch 20/32\n",
      "11995/11995 [==============================] - 2s 138us/step - loss: 1.3648 - acc: 0.3864 - val_loss: 1.4179 - val_acc: 0.3656\n",
      "Epoch 21/32\n",
      "11995/11995 [==============================] - 2s 140us/step - loss: 1.3632 - acc: 0.3864 - val_loss: 1.4164 - val_acc: 0.3616\n",
      "Epoch 22/32\n",
      "11995/11995 [==============================] - 2s 144us/step - loss: 1.3651 - acc: 0.3861 - val_loss: 1.4297 - val_acc: 0.3619\n",
      "Epoch 23/32\n",
      "11995/11995 [==============================] - 2s 145us/step - loss: 1.3610 - acc: 0.3907 - val_loss: 1.4211 - val_acc: 0.3619\n",
      "Epoch 24/32\n",
      "11995/11995 [==============================] - 2s 138us/step - loss: 1.3594 - acc: 0.3902 - val_loss: 1.4109 - val_acc: 0.3612\n",
      "Epoch 25/32\n",
      "11995/11995 [==============================] - 2s 136us/step - loss: 1.3563 - acc: 0.3967 - val_loss: 1.4243 - val_acc: 0.3626\n",
      "Epoch 26/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3551 - acc: 0.3935 - val_loss: 1.4269 - val_acc: 0.3686\n",
      "Epoch 27/32\n",
      "11995/11995 [==============================] - 2s 135us/step - loss: 1.3527 - acc: 0.3938 - val_loss: 1.4271 - val_acc: 0.3526\n",
      "Epoch 28/32\n",
      "11995/11995 [==============================] - 2s 133us/step - loss: 1.3551 - acc: 0.3907 - val_loss: 1.4270 - val_acc: 0.3589\n",
      "Epoch 29/32\n",
      "11995/11995 [==============================] - 2s 131us/step - loss: 1.3492 - acc: 0.3942 - val_loss: 1.4263 - val_acc: 0.3582\n",
      "Epoch 30/32\n",
      "11995/11995 [==============================] - 2s 128us/step - loss: 1.3511 - acc: 0.3981 - val_loss: 1.4292 - val_acc: 0.3652\n",
      "Epoch 31/32\n",
      "11995/11995 [==============================] - 2s 130us/step - loss: 1.3471 - acc: 0.3955 - val_loss: 1.4365 - val_acc: 0.3612\n",
      "Epoch 32/32\n",
      "11995/11995 [==============================] - 2s 132us/step - loss: 1.3401 - acc: 0.4059 - val_loss: 1.4352 - val_acc: 0.3599\n"
     ]
    }
   ],
   "source": [
    "# Attribute model data\n",
    "X_attr, Y_attr = convert_for_single_axis(X, Y, ax=0)\n",
    "\n",
    "# Image-free model\n",
    "attr_clf = ImageFreeModel\n",
    "\n",
    "# Train the model\n",
    "attr_clf = train_model(attr_clf, X_attr, Y_attr, epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_f5oILJKvt1_"
   },
   "outputs": [],
   "source": [
    "# Create inputs for convolutional model\n",
    "X_conv, Y_conv = convert_for_all(X, Y)\n",
    "X_conv = X_conv[1]\n",
    "print(X_conv.shape)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image generator for training\n",
    "def make_generator(X):\n",
    "    gen = ImageDataGenerator(\n",
    "            rotation_range=40,\n",
    "            zoom_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "    )\n",
    "    gen.fit(X)\n",
    "    return gen\n",
    "\n",
    "Y_conv = to_categorical(Y_conv)\n",
    "\n",
    "# Validation split\n",
    "(X_train, Y_train), (X_valid, Y_valid) = split(X_conv, Y_conv)\n",
    "print('Training points:', len(Y_train))\n",
    "print('Validation points:', len(Y_valid))\n",
    "print('Total points:', len(Y))\n",
    "print(X_train.shape, X_valid.shape)\n",
    "\n",
    "train_gen = make_generator(X_train).flow(X_train, Y_train, batch_size=10)\n",
    "\n",
    "# Build a model\n",
    "conv_clf = SingleImageModel((X_train, Y_train), (X_valid, Y_valid))\n",
    "\n",
    "# Train the model\n",
    "conv_clf.compile()\n",
    "conv_clf.model.fit_generator(train_gen, steps_per_epoch = len(X_train) // 32, epochs=8, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "\n",
    "del X_conv\n",
    "del Y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rw0Y-oo4_IV-"
   },
   "outputs": [],
   "source": [
    "attr_clf.model.predict(X_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kc_Qv1ongWk8"
   },
   "outputs": [],
   "source": [
    "# Create inputs for convolutional model\n",
    "X_conv, Y_conv = convert_for_all(X, Y)\n",
    "print('Built data')\n",
    "print([x.shape for x in X_conv])\n",
    "print(Y_conv.shape)\n",
    "\n",
    "# Build a model\n",
    "union_clf = lambda tr, tst: UnionModel([attr_clf, conv_clf], tr, tst, freeze=True)\n",
    "\n",
    "# Train the model\n",
    "union_clf = train_model(union_clf, X_conv, Y_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7P2rPR5UbhO"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6Cat105rUYtP",
    "outputId": "54df7d82-1b77-41f0-a868-36784a8e538b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be loaded from data/test_images/picked_pictures.npy\n"
     ]
    }
   ],
   "source": [
    "# Get the test data\n",
    "X, ids = load_train_data(is_train=False)\n",
    "X = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWmhXvpJVGrW"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "Y = attr_clf.model.predict(X)\n",
    "Y = np.argmax(Y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105
    },
    "colab_type": "code",
    "id": "o18H5BcoV4lG",
    "outputId": "96448e7a-e1c5-48dd-8f4b-b11705886529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PetID  AdoptionSpeed\n",
      "0     378fcc4fc              4\n",
      "1     73c10e136              4\n",
      "2     72000c4c5              4\n",
      "3     e147a4b9f              4\n",
      "4     43fbba852              4\n",
      "5     77a490ec9              4\n",
      "6     28c4b1b13              4\n",
      "7     d1eada628              4\n",
      "8     d134dec34              4\n",
      "9     bcd464bb8              4\n",
      "10    4e21958c3              4\n",
      "11    7b070aed6              4\n",
      "12    ff8d0708f              4\n",
      "13    f1e6c9bf3              4\n",
      "14    248914c05              4\n",
      "15    948002885              4\n",
      "16    111e67cd2              4\n",
      "17    4f4b2ede1              4\n",
      "18    d77fca061              4\n",
      "19    ac9fb74b9              4\n",
      "20    47ef39e7a              4\n",
      "21    c69ee9807              4\n",
      "22    62dcf8ecb              4\n",
      "23    4df1d19d6              4\n",
      "24    e8ef8455e              4\n",
      "25    cbd23bc17              2\n",
      "26    4d1a91ccf              2\n",
      "27    004ee5cf7              4\n",
      "28    95fad0a75              4\n",
      "29    64341b5db              4\n",
      "...         ...            ...\n",
      "3918  4586798a6              4\n",
      "3919  e5ec7709d              4\n",
      "3920  fa0b958ae              4\n",
      "3921  85fda19ab              4\n",
      "3922  d6a2fa83e              4\n",
      "3923  08f25f7da              4\n",
      "3924  a159e317f              4\n",
      "3925  09582e51b              1\n",
      "3926  0c9cc3c3d              1\n",
      "3927  fd6a10dd8              2\n",
      "3928  3b22e5249              4\n",
      "3929  62abaa505              4\n",
      "3930  d274a7103              4\n",
      "3931  4f244a307              3\n",
      "3932  34e4c214d              2\n",
      "3933  67b8ae43b              1\n",
      "3934  285a40127              1\n",
      "3935  ce637df13              4\n",
      "3936  e07d8debe              4\n",
      "3937  5c23692a4              4\n",
      "3938  4dc690fca              2\n",
      "3939  40739eff7              1\n",
      "3940  e90b93c02              2\n",
      "3941  0a4831022              4\n",
      "3942  d24a644d5              4\n",
      "3943  6bde0667b              4\n",
      "3944  e25b59349              2\n",
      "3945  10bc6fc6a              1\n",
      "3946  2d7a91c59              2\n",
      "3947  e5bbe3e54              2\n",
      "\n",
      "[3948 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save the results to a file\n",
    "df = pd.DataFrame({\n",
    "    'PetID': ids,\n",
    "    'AdoptionSpeed':Y\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "OurModels.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
